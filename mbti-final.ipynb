{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-09T10:40:33.237532Z",
     "iopub.status.busy": "2024-12-09T10:40:33.237154Z",
     "iopub.status.idle": "2024-12-09T10:40:33.248386Z",
     "shell.execute_reply": "2024-12-09T10:40:33.247299Z",
     "shell.execute_reply.started": "2024-12-09T10:40:33.237498Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/Documents/mestrado/disciplinas/inteligencia-artificial/projeto-final/ia-2024-2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_text_separated</th>\n",
       "      <th>tfidf_embedding</th>\n",
       "      <th>glove_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@Pericles216 @HierBeforeTheAC @Sachinettiyil T...</td>\n",
       "      <td>intj</td>\n",
       "      <td>pope infallible catholic dogma doesnt mean per...</td>\n",
       "      <td>[pope infallible catholic dogma doesnt mean, p...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019...</td>\n",
       "      <td>[-0.04726143, -0.060535315, -0.057487372, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@Hispanthicckk Being you makes you look cute||...</td>\n",
       "      <td>intj</td>\n",
       "      <td>makes look cute fun peeling bored less sweetie...</td>\n",
       "      <td>[makes look cute, fun peeling, bored, less, sw...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.049909562, -0.022831392, -0.028013704, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@Alshymi Les balles sont réelles et sont tirée...</td>\n",
       "      <td>intj</td>\n",
       "      <td>les balles sont relles et sont tires trs rapid...</td>\n",
       "      <td>[les balles sont relles et sont tires trs rapi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022...</td>\n",
       "      <td>[-0.02637649, 0.002697029, -0.050253987, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm like entp but idiotic|||Hey boy, do you wa...</td>\n",
       "      <td>intj</td>\n",
       "      <td>im like entp idiotic hey boy want watch twitch...</td>\n",
       "      <td>[im like entp idiotic, hey boy want watch twit...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.0019069636, -0.0014414503, 0.00036121352, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@kaeshurr1 Give it to @ZargarShanif ... He has...</td>\n",
       "      <td>intj</td>\n",
       "      <td>give pica since childhood say qubool hai dm ge...</td>\n",
       "      <td>[give pica since childhood, say qubool hai dm,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0427088751511...</td>\n",
       "      <td>[-0.08774337, -0.06754079, -0.03461329, 0.0125...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text label  \\\n",
       "0           0  @Pericles216 @HierBeforeTheAC @Sachinettiyil T...  intj   \n",
       "1           1  @Hispanthicckk Being you makes you look cute||...  intj   \n",
       "2           2  @Alshymi Les balles sont réelles et sont tirée...  intj   \n",
       "3           3  I'm like entp but idiotic|||Hey boy, do you wa...  intj   \n",
       "4           4  @kaeshurr1 Give it to @ZargarShanif ... He has...  intj   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  pope infallible catholic dogma doesnt mean per...   \n",
       "1  makes look cute fun peeling bored less sweetie...   \n",
       "2  les balles sont relles et sont tires trs rapid...   \n",
       "3  im like entp idiotic hey boy want watch twitch...   \n",
       "4  give pica since childhood say qubool hai dm ge...   \n",
       "\n",
       "                              cleaned_text_separated  \\\n",
       "0  [pope infallible catholic dogma doesnt mean, p...   \n",
       "1  [makes look cute, fun peeling, bored, less, sw...   \n",
       "2  [les balles sont relles et sont tires trs rapi...   \n",
       "3  [im like entp idiotic, hey boy want watch twit...   \n",
       "4  [give pica since childhood, say qubool hai dm,...   \n",
       "\n",
       "                                     tfidf_embedding  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0427088751511...   \n",
       "\n",
       "                                     glove_embedding  \n",
       "0  [-0.04726143, -0.060535315, -0.057487372, 0.00...  \n",
       "1  [-0.049909562, -0.022831392, -0.028013704, -0....  \n",
       "2  [-0.02637649, 0.002697029, -0.050253987, -0.02...  \n",
       "3  [-0.0019069636, -0.0014414503, 0.00036121352, ...  \n",
       "4  [-0.08774337, -0.06754079, -0.03461329, 0.0125...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('cleaned_dataset.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n"
     ]
    }
   ],
   "source": [
    "mbti_personality_type_twitter_dataset_path = kagglehub.dataset_download('mazlumi/mbti-personality-type-twitter-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n"
     ]
    }
   ],
   "source": [
    "glove6b300dtxt_path = kagglehub.dataset_download('thanakomsn/glove6b300dtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.cache/kagglehub/datasets/mazlumi/mbti-personality-type-twitter-dataset/versions/1\n",
      "/home/guilherme/.cache/kagglehub/datasets/thanakomsn/glove6b300dtxt/versions/1\n"
     ]
    }
   ],
   "source": [
    "print(mbti_personality_type_twitter_dataset_path)\n",
    "print(glove6b300dtxt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.cache/kagglehub/datasets/mazlumi/mbti-personality-type-twitter-dataset/versions/1/twitter_MBTI.csv\n",
      "/home/guilherme/.cache/kagglehub/datasets/thanakomsn/glove6b300dtxt/versions/1/glove.6B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(mbti_personality_type_twitter_dataset_path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "for dirname, _, filenames in os.walk(glove6b300dtxt_path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:40:39.477629Z",
     "iopub.status.busy": "2024-12-09T10:40:39.477290Z",
     "iopub.status.idle": "2024-12-09T10:40:42.395952Z",
     "shell.execute_reply": "2024-12-09T10:40:42.394800Z",
     "shell.execute_reply.started": "2024-12-09T10:40:39.477597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(mbti_personality_type_twitter_dataset_path+'/twitter_MBTI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:40:43.786760Z",
     "iopub.status.busy": "2024-12-09T10:40:43.786375Z",
     "iopub.status.idle": "2024-12-09T10:40:45.479265Z",
     "shell.execute_reply": "2024-12-09T10:40:45.477721Z",
     "shell.execute_reply.started": "2024-12-09T10:40:43.786726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/guilherme/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/guilherme/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/guilherme/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download NLTK data files (if not already done)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define stopwords (optional)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean a single tweet\n",
    "def clean_tweet(tweet):\n",
    "    # Remove HTML tags\n",
    "    tweet = re.sub(r'<.*?>', '', tweet)\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www\\S+', '', tweet)\n",
    "    # Remove mentions\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    # Remove special characters and digits\n",
    "    tweet = re.sub(r'[^A-Za-z\\s]', '', tweet)\n",
    "    # Convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Tokenize and remove stopwords (optional)\n",
    "    tokens = word_tokenize(tweet)\n",
    "    cleaned_tweet = ' '.join([word for word in tokens if word not in stop_words])\n",
    "    return cleaned_tweet\n",
    "\n",
    "# Split tweets by '|||' and clean them\n",
    "def process_user_tweets(tweets):\n",
    "    # Split tweets\n",
    "    tweet_list = tweets.split('|||')\n",
    "    # Clean each tweet\n",
    "    cleaned_tweets = [clean_tweet(tweet) for tweet in tweet_list]\n",
    "    # Combine cleaned tweets\n",
    "    return ' '.join(cleaned_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:40:45.586340Z",
     "iopub.status.busy": "2024-12-09T10:40:45.585768Z",
     "iopub.status.idle": "2024-12-09T10:42:33.658924Z",
     "shell.execute_reply": "2024-12-09T10:42:33.657661Z",
     "shell.execute_reply.started": "2024-12-09T10:40:45.586296Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@Pericles216 @HierBeforeTheAC @Sachinettiyil T...</td>\n",
       "      <td>intj</td>\n",
       "      <td>pope infallible catholic dogma doesnt mean per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@Hispanthicckk Being you makes you look cute||...</td>\n",
       "      <td>intj</td>\n",
       "      <td>makes look cute fun peeling bored less sweetie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@Alshymi Les balles sont réelles et sont tirée...</td>\n",
       "      <td>intj</td>\n",
       "      <td>les balles sont relles et sont tires trs rapid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm like entp but idiotic|||Hey boy, do you wa...</td>\n",
       "      <td>intj</td>\n",
       "      <td>im like entp idiotic hey boy want watch twitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@kaeshurr1 Give it to @ZargarShanif ... He has...</td>\n",
       "      <td>intj</td>\n",
       "      <td>give pica since childhood say qubool hai dm ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text label  \\\n",
       "0           0  @Pericles216 @HierBeforeTheAC @Sachinettiyil T...  intj   \n",
       "1           1  @Hispanthicckk Being you makes you look cute||...  intj   \n",
       "2           2  @Alshymi Les balles sont réelles et sont tirée...  intj   \n",
       "3           3  I'm like entp but idiotic|||Hey boy, do you wa...  intj   \n",
       "4           4  @kaeshurr1 Give it to @ZargarShanif ... He has...  intj   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  pope infallible catholic dogma doesnt mean per...  \n",
       "1  makes look cute fun peeling bored less sweetie...  \n",
       "2  les balles sont relles et sont tires trs rapid...  \n",
       "3  im like entp idiotic hey boy want watch twitch...  \n",
       "4  give pica since childhood say qubool hai dm ge...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply cleaning to the dataset\n",
    "df['cleaned_text'] = df['text'].apply(process_user_tweets)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:42:33.661581Z",
     "iopub.status.busy": "2024-12-09T10:42:33.661149Z",
     "iopub.status.idle": "2024-12-09T10:44:21.899658Z",
     "shell.execute_reply": "2024-12-09T10:44:21.898576Z",
     "shell.execute_reply.started": "2024-12-09T10:42:33.661534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_text_separated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@Pericles216 @HierBeforeTheAC @Sachinettiyil T...</td>\n",
       "      <td>intj</td>\n",
       "      <td>pope infallible catholic dogma doesnt mean per...</td>\n",
       "      <td>[pope infallible catholic dogma doesnt mean, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@Hispanthicckk Being you makes you look cute||...</td>\n",
       "      <td>intj</td>\n",
       "      <td>makes look cute fun peeling bored less sweetie...</td>\n",
       "      <td>[makes look cute, fun peeling, bored, less, sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@Alshymi Les balles sont réelles et sont tirée...</td>\n",
       "      <td>intj</td>\n",
       "      <td>les balles sont relles et sont tires trs rapid...</td>\n",
       "      <td>[les balles sont relles et sont tires trs rapi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm like entp but idiotic|||Hey boy, do you wa...</td>\n",
       "      <td>intj</td>\n",
       "      <td>im like entp idiotic hey boy want watch twitch...</td>\n",
       "      <td>[im like entp idiotic, hey boy want watch twit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@kaeshurr1 Give it to @ZargarShanif ... He has...</td>\n",
       "      <td>intj</td>\n",
       "      <td>give pica since childhood say qubool hai dm ge...</td>\n",
       "      <td>[give pica since childhood, say qubool hai dm,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text label  \\\n",
       "0           0  @Pericles216 @HierBeforeTheAC @Sachinettiyil T...  intj   \n",
       "1           1  @Hispanthicckk Being you makes you look cute||...  intj   \n",
       "2           2  @Alshymi Les balles sont réelles et sont tirée...  intj   \n",
       "3           3  I'm like entp but idiotic|||Hey boy, do you wa...  intj   \n",
       "4           4  @kaeshurr1 Give it to @ZargarShanif ... He has...  intj   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  pope infallible catholic dogma doesnt mean per...   \n",
       "1  makes look cute fun peeling bored less sweetie...   \n",
       "2  les balles sont relles et sont tires trs rapid...   \n",
       "3  im like entp idiotic hey boy want watch twitch...   \n",
       "4  give pica since childhood say qubool hai dm ge...   \n",
       "\n",
       "                              cleaned_text_separated  \n",
       "0  [pope infallible catholic dogma doesnt mean, p...  \n",
       "1  [makes look cute, fun peeling, bored, less, sw...  \n",
       "2  [les balles sont relles et sont tires trs rapi...  \n",
       "3  [im like entp idiotic, hey boy want watch twit...  \n",
       "4  [give pica since childhood, say qubool hai dm,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text_separated'] = df['text'].map(lambda x: x.split('|||')).\\\n",
    "                                apply(lambda x: [clean_tweet(tweet) for tweet in x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:44:21.901605Z",
     "iopub.status.busy": "2024-12-09T10:44:21.901165Z",
     "iopub.status.idle": "2024-12-09T10:46:11.038257Z",
     "shell.execute_reply": "2024-12-09T10:46:11.036871Z",
     "shell.execute_reply.started": "2024-12-09T10:44:21.901559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              tokens_aggregated_nltk  \\\n",
      "0  [pope, infallible, catholic, dogma, doesnt, me...   \n",
      "1  [makes, look, cute, fun, peeling, bored, less,...   \n",
      "2  [les, balles, sont, relles, et, sont, tires, t...   \n",
      "3  [im, like, entp, idiotic, hey, boy, want, watc...   \n",
      "4  [give, pica, since, childhood, say, qubool, ha...   \n",
      "\n",
      "                               tokens_separated_nltk  \n",
      "0  [[pope, infallible, catholic, dogma, doesnt, m...  \n",
      "1  [[makes, look, cute], [fun, peeling], [bored],...  \n",
      "2  [[les, balles, sont, relles, et, sont, tires, ...  \n",
      "3  [[im, like, entp, idiotic], [hey, boy, want, w...  \n",
      "4  [[give, pica, since, childhood], [say, qubool,...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize aggregated tweets\n",
    "df['tokens_aggregated_nltk'] = df['cleaned_text'].apply(word_tokenize)\n",
    "\n",
    "# Tokenize separated tweets\n",
    "df['tokens_separated_nltk'] = df['cleaned_text_separated'].apply(\n",
    "    lambda tweet_list: [word_tokenize(tweet) for tweet in tweet_list]\n",
    ")\n",
    "\n",
    "print(df[['tokens_aggregated_nltk', 'tokens_separated_nltk']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:46:11.041390Z",
     "iopub.status.busy": "2024-12-09T10:46:11.040992Z",
     "iopub.status.idle": "2024-12-09T10:48:10.434539Z",
     "shell.execute_reply": "2024-12-09T10:48:10.433146Z",
     "shell.execute_reply.started": "2024-12-09T10:46:11.041356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb57f187f21f480eb71d06e635753334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff48b3a02c7458684b4f9350530bbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25222a96daa64026b1d4ba892a980620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06fc2505e7842459d6af34b3b027f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              tokens_aggregated_bert  \\\n",
      "0  [101, 4831, 1999, 13976, 7028, 3234, 3899, 286...   \n",
      "1  [101, 3084, 2298, 10140, 4569, 28241, 11471, 2...   \n",
      "2  [101, 4649, 3608, 2229, 2365, 2102, 2128, 2043...   \n",
      "3  [101, 10047, 2066, 4372, 25856, 10041, 2594, 4...   \n",
      "4  [101, 2507, 27263, 2050, 2144, 5593, 2360, 242...   \n",
      "\n",
      "                               tokens_separated_bert  \n",
      "0  [[101, 4831, 1999, 13976, 7028, 3234, 3899, 28...  \n",
      "1  [[101, 3084, 2298, 10140, 102], [101, 4569, 28...  \n",
      "2  [[101, 4649, 3608, 2229, 2365, 2102, 2128, 204...  \n",
      "3  [[101, 10047, 2066, 4372, 25856, 10041, 2594, ...  \n",
      "4  [[101, 2507, 27263, 2050, 2144, 5593, 102], [1...  \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pre-trained tokenizer (e.g., BERT tokenizer)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize aggregated tweets\n",
    "df['tokens_aggregated_bert'] = df['cleaned_text'].apply(\n",
    "    lambda text: tokenizer.encode(text, max_length=512, truncation=True)\n",
    ")\n",
    "\n",
    "# Tokenize separated tweets without truncation (each tweet is likely shorter)\n",
    "df['tokens_separated_bert'] = df['cleaned_text_separated'].apply(\n",
    "    lambda tweet_list: [tokenizer.encode(tweet, max_length=512, truncation=True) for tweet in tweet_list]\n",
    ")\n",
    "\n",
    "print(df[['tokens_aggregated_bert', 'tokens_separated_bert']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:48:10.436808Z",
     "iopub.status.busy": "2024-12-09T10:48:10.436255Z",
     "iopub.status.idle": "2024-12-09T10:48:16.862878Z",
     "shell.execute_reply": "2024-12-09T10:48:16.861760Z",
     "shell.execute_reply.started": "2024-12-09T10:48:10.436771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        cleaned_text  \\\n",
      "0  pope infallible catholic dogma doesnt mean per...   \n",
      "1  makes look cute fun peeling bored less sweetie...   \n",
      "2  les balles sont relles et sont tires trs rapid...   \n",
      "3  im like entp idiotic hey boy want watch twitch...   \n",
      "4  give pica since childhood say qubool hai dm ge...   \n",
      "\n",
      "                                     tfidf_embedding  \n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019...  \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022...  \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0427088751511...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import dump \n",
    "\n",
    "# Use aggregated tweets for TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to top 5000 features\n",
    "tfidf_embeddings = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Save the vectorizer for later use\n",
    "dump(vectorizer, \"tfidf_vectorizer.joblib\")\n",
    "\n",
    "# Save embeddings to DataFrame\n",
    "df['tfidf_embedding'] = list(tfidf_embeddings.toarray())\n",
    "\n",
    "print(df[['cleaned_text', 'tfidf_embedding']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:48:16.864490Z",
     "iopub.status.busy": "2024-12-09T10:48:16.864188Z",
     "iopub.status.idle": "2024-12-09T10:50:07.758152Z",
     "shell.execute_reply": "2024-12-09T10:50:07.756910Z",
     "shell.execute_reply.started": "2024-12-09T10:48:16.864461Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        cleaned_text  \\\n",
      "0  pope infallible catholic dogma doesnt mean per...   \n",
      "1  makes look cute fun peeling bored less sweetie...   \n",
      "2  les balles sont relles et sont tires trs rapid...   \n",
      "3  im like entp idiotic hey boy want watch twitch...   \n",
      "4  give pica since childhood say qubool hai dm ge...   \n",
      "\n",
      "                                     glove_embedding  \n",
      "0  [-0.04726143, -0.060535315, -0.057487372, 0.00...  \n",
      "1  [-0.049909562, -0.022831392, -0.028013704, -0....  \n",
      "2  [-0.02637649, 0.002697029, -0.050253987, -0.02...  \n",
      "3  [-0.0019069636, -0.0014414503, 0.00036121352, ...  \n",
      "4  [-0.08774337, -0.06754079, -0.03461329, 0.0125...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained GloVe vectors (download from https://nlp.stanford.edu/projects/glove/)\n",
    "glove_path = glove6b300dtxt_path + '/glove.6B.300d.txt'  # Adjust path and file size as needed\n",
    "word_vectors = KeyedVectors.load_word2vec_format(glove_path, binary=False, no_header=True)\n",
    "\n",
    "# Function to get sentence embeddings by averaging word embeddings\n",
    "def get_sentence_embedding(text, word_vectors):\n",
    "    tokens = text.split()  # Simple split, adapt if needed\n",
    "    embeddings = [word_vectors[word] for word in tokens if word in word_vectors]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word_vectors.vector_size)\n",
    "\n",
    "# Apply to aggregated tweets\n",
    "df['glove_embedding'] = df['cleaned_text'].apply(\n",
    "    lambda text: get_sentence_embedding(text, word_vectors)\n",
    ")\n",
    "\n",
    "print(df[['cleaned_text', 'glove_embedding']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:54:57.060846Z",
     "iopub.status.busy": "2024-12-08T23:54:57.059980Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59d683908ed47eea914fa5092f0276e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "# # Load a pre-trained BERT model and tokenizer\n",
    "# model_name = \"bert-base-uncased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# # Function to get BERT embeddings for aggregated tweets\n",
    "# def get_bert_embedding(text):\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     # Take the CLS token's embedding for classification\n",
    "#     cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "#     return cls_embedding.numpy()\n",
    "\n",
    "# # Apply to aggregated tweets\n",
    "# df['bert_embedding'] = df['cleaned_text'].apply(get_bert_embedding)\n",
    "\n",
    "# print(df[['cleaned_text', 'bert_embedding']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:50:07.760236Z",
     "iopub.status.busy": "2024-12-09T10:50:07.759794Z",
     "iopub.status.idle": "2024-12-09T10:50:38.382623Z",
     "shell.execute_reply": "2024-12-09T10:50:38.381499Z",
     "shell.execute_reply.started": "2024-12-09T10:50:07.760201Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to cleaned_dataset.pickle\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "output_path = 'cleaned_dataset.pickle'\n",
    "df.to_pickle(output_path)\n",
    "\n",
    "print(f\"DataFrame saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T11:02:32.277906Z",
     "iopub.status.busy": "2024-12-09T11:02:32.277156Z",
     "iopub.status.idle": "2024-12-09T11:02:32.298073Z",
     "shell.execute_reply": "2024-12-09T11:02:32.296773Z",
     "shell.execute_reply.started": "2024-12-09T11:02:32.277865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming 'label' column exists in the dataframe\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "labels_one_hot = encoder.fit_transform(df[['label']])\n",
    "\n",
    "# Add to the dataframe or save separately\n",
    "df['label_one_hot'] = list(labels_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T11:03:10.844417Z",
     "iopub.status.busy": "2024-12-09T11:03:10.843946Z",
     "iopub.status.idle": "2024-12-09T11:03:10.857428Z",
     "shell.execute_reply": "2024-12-09T11:03:10.856008Z",
     "shell.execute_reply.started": "2024-12-09T11:03:10.844375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "infp    1282\n",
      "infj    1057\n",
      "intp     811\n",
      "intj     781\n",
      "enfp     729\n",
      "entp     577\n",
      "enfj     518\n",
      "isfp     367\n",
      "isfj     364\n",
      "istp     327\n",
      "entj     279\n",
      "istj     259\n",
      "esfp     174\n",
      "esfj     105\n",
      "estp     100\n",
      "estj      81\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of classes\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T11:08:01.129165Z",
     "iopub.status.busy": "2024-12-09T11:08:01.128746Z",
     "iopub.status.idle": "2024-12-09T11:08:01.134618Z",
     "shell.execute_reply": "2024-12-09T11:08:01.133445Z",
     "shell.execute_reply.started": "2024-12-09T11:08:01.129131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# # Choose between SMOTE or RandomUnderSampler\n",
    "# oversample = SMOTE(random_state=42)  # Use for oversampling\n",
    "# undersample = RandomUnderSampler(random_state=42)  # Use for undersampling\n",
    "\n",
    "# # Example: Oversample\n",
    "# X = df['tfidf_embedding']  # Use your tfidf embedding matrix\n",
    "# y = df['label']  # Original labels\n",
    "# X_resampled, y_resampled = oversample.fit_resample(X, y)\n",
    "\n",
    "# # Encode labels as one-hot\n",
    "# y_resampled_one_hot = encoder.fit_transform(y_resampled.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T11:09:38.307122Z",
     "iopub.status.busy": "2024-12-09T11:09:38.306646Z",
     "iopub.status.idle": "2024-12-09T11:09:41.152300Z",
     "shell.execute_reply": "2024-12-09T11:09:41.151155Z",
     "shell.execute_reply.started": "2024-12-09T11:09:38.307085Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/Documents/mestrado/disciplinas/inteligencia-artificial/projeto-final/ia-2024-2/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/home/guilherme/Documents/mestrado/disciplinas/inteligencia-artificial/projeto-final/ia-2024-2/lib/python3.9/site-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled X shape: (20512, 5000)\n",
      "Resampled X_glove shape: (20512, 300)\n",
      "Resampled y distribution: (array(['enfj', 'enfp', 'entj', 'entp', 'esfj', 'esfp', 'estj', 'estp',\n",
      "       'infj', 'infp', 'intj', 'intp', 'isfj', 'isfp', 'istj', 'istp'],\n",
      "      dtype=object), array([1282, 1282, 1282, 1282, 1282, 1282, 1282, 1282, 1282, 1282, 1282,\n",
      "       1282, 1282, 1282, 1282, 1282]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/Documents/mestrado/disciplinas/inteligencia-artificial/projeto-final/ia-2024-2/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/home/guilherme/Documents/mestrado/disciplinas/inteligencia-artificial/projeto-final/ia-2024-2/lib/python3.9/site-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Convert tfidf_embedding to NumPy array\n",
    "X = np.array(df['tfidf_embedding'].tolist())\n",
    "X_glove = np.array(df['glove_embedding'].tolist())\n",
    "\n",
    "# Ensure labels are categorical\n",
    "y = df['label']\n",
    "\n",
    "# Apply SMOTE for oversampling\n",
    "oversample = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = oversample.fit_resample(X, y)\n",
    "X_glove_resampled, y_resampled = oversample.fit_resample(X_glove, y)\n",
    "\n",
    "# Encode labels as one-hot\n",
    "y_resampled_one_hot = encoder.fit_transform(y_resampled.values.reshape(-1, 1))\n",
    "\n",
    "print(\"Resampled X shape:\", X_resampled.shape)\n",
    "print(\"Resampled X_glove shape:\", X_glove_resampled.shape)\n",
    "print(\"Resampled y distribution:\", np.unique(y_resampled, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T11:10:03.018456Z",
     "iopub.status.busy": "2024-12-09T11:10:03.016741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the data\n",
    "X_train_oh, X_test_oh, y_train_oh, y_test_oh = train_test_split(\n",
    "    X_resampled, y_resampled_one_hot, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define candidate models and their hyperparameters\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [LogisticRegression()],\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__C': [0.1, 1.0, 10.0],\n",
    "        'model__solver': ['lbfgs'],\n",
    "    },\n",
    "    # {\n",
    "    #     'model': [SVC()],\n",
    "    #     'model__kernel': ['linear', 'rbf'],\n",
    "    #     'model__C': [0.1, 1.0, 10.0],\n",
    "    # },\n",
    "]\n",
    "\n",
    "param_grid_oh = [\n",
    "    {\n",
    "        'model': [RandomForestClassifier()],\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [None, 10, 20],\n",
    "    },\n",
    "    {\n",
    "        'model': [XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', tree_method='gpu_hist')],\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.01, 0.1],\n",
    "        'model__max_depth': [3, 6],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV 1/3] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs;, score=0.469 total time=   5.3s\n",
      "[CV 2/3] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs;, score=0.487 total time=   4.7s\n",
      "[CV 3/3] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs;, score=0.473 total time=   4.9s\n",
      "[CV 1/3] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__solver=lbfgs;, score=0.701 total time=  24.2s\n",
      "[CV 2/3] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__solver=lbfgs;, score=0.710 total time=  19.0s\n",
      "[CV 3/3] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__solver=lbfgs;, score=0.713 total time=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/Documents/mestrado/disciplinas/inteligencia-artificial/projeto-final/ia-2024-2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__solver=lbfgs;, score=0.801 total time=  28.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/Documents/mestrado/disciplinas/inteligencia-artificial/projeto-final/ia-2024-2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__solver=lbfgs;, score=0.801 total time=  27.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/Documents/mestrado/disciplinas/inteligencia-artificial/projeto-final/ia-2024-2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__solver=lbfgs;, score=0.804 total time=  28.3s\n",
      "Best Model: Pipeline(steps=[('model', LogisticRegression(C=10.0))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        enfj       0.80      0.90      0.84       256\n",
      "        enfp       0.77      0.70      0.73       279\n",
      "        entj       0.91      0.96      0.93       248\n",
      "        entp       0.78      0.85      0.81       236\n",
      "        esfj       0.99      1.00      0.99       251\n",
      "        esfp       0.95      0.98      0.96       245\n",
      "        estj       0.99      0.99      0.99       269\n",
      "        estp       1.00      1.00      1.00       263\n",
      "        infj       0.60      0.56      0.58       259\n",
      "        infp       0.55      0.48      0.51       248\n",
      "        intj       0.75      0.71      0.73       259\n",
      "        intp       0.76      0.61      0.68       274\n",
      "        isfj       0.88      0.90      0.89       252\n",
      "        isfp       0.85      0.93      0.89       241\n",
      "        istj       0.92      0.99      0.95       246\n",
      "        istp       0.91      0.95      0.93       277\n",
      "\n",
      "    accuracy                           0.84      4103\n",
      "   macro avg       0.84      0.84      0.84      4103\n",
      "weighted avg       0.84      0.84      0.84      4103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/Documents/mestrado/disciplinas/inteligencia-artificial/projeto-final/ia-2024-2/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('model', LogisticRegression())  # Placeholder, will be replaced in GridSearchCV\n",
    "])\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "print(\"Best Model:\", grid.best_estimator_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_regression.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(grid.best_estimator_, 'best_model_regression.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('model', LogisticRegression(C=10.0))],\n",
       " 'transform_input': None,\n",
       " 'verbose': False,\n",
       " 'model': LogisticRegression(C=10.0),\n",
       " 'model__C': 10.0,\n",
       " 'model__class_weight': None,\n",
       " 'model__dual': False,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__intercept_scaling': 1,\n",
       " 'model__l1_ratio': None,\n",
       " 'model__max_iter': 100,\n",
       " 'model__multi_class': 'deprecated',\n",
       " 'model__n_jobs': None,\n",
       " 'model__penalty': 'l2',\n",
       " 'model__random_state': None,\n",
       " 'model__solver': 'lbfgs',\n",
       " 'model__tol': 0.0001,\n",
       " 'model__verbose': 0,\n",
       " 'model__warm_start': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = load('best_model_regression.joblib')\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('model', LogisticRegression())  # Placeholder, will be replaced in GridSearchCV\n",
    "])\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(pipeline, param_grid_oh, cv=3, scoring='accuracy', verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "print(\"Best Model:\", grid.best_estimator_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7811, 300), (20512, 300))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.stack(df['glove_embedding'].values)  # Ensure embeddings are stacked correctly\n",
    "y = np.stack(df['label_one_hot'].values)   # Stack one-hot encoded labels\n",
    "X2 = np.stack(X_glove_resampled)\n",
    "y2 = np.stack(y_resampled_one_hot)\n",
    "\n",
    "X.shape, X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "# X = np.stack(df['glove_embedding'].values)  # Ensure embeddings are stacked correctly\n",
    "# y = np.stack(df['label_one_hot'].values)   # Stack one-hot encoded labels\n",
    "X2 = np.stack(X_glove_resampled)\n",
    "y2 = np.stack(y_resampled_one_hot)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "num_classes = y_train.shape[1]  # Number of classes from one-hot encoding\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(128, activation='relu', input_shape=(300,)),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(512, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(num_classes, activation='softmax')  # Multi-class output\n",
    "# ])\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(300,), kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1024, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']              \n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.1768 - loss: 3.1846 - val_accuracy: 0.1550 - val_loss: 3.1174\n",
      "Epoch 2/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.1768 - loss: 2.9966 - val_accuracy: 0.1209 - val_loss: 3.0445\n",
      "Epoch 3/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.1887 - loss: 2.8940 - val_accuracy: 0.1011 - val_loss: 3.4285\n",
      "Epoch 4/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.1925 - loss: 2.8975 - val_accuracy: 0.0819 - val_loss: 4.8907\n",
      "Epoch 5/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.1950 - loss: 2.8855 - val_accuracy: 0.1450 - val_loss: 3.1927\n",
      "Epoch 6/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2025 - loss: 2.8723 - val_accuracy: 0.1365 - val_loss: 3.1257\n",
      "Epoch 7/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.2075 - loss: 2.8844 - val_accuracy: 0.1048 - val_loss: 3.1771\n",
      "Epoch 8/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2106 - loss: 2.8980 - val_accuracy: 0.0894 - val_loss: 3.3910\n",
      "Epoch 9/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2128 - loss: 2.9169 - val_accuracy: 0.1903 - val_loss: 2.9807\n",
      "Epoch 10/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2134 - loss: 2.8756 - val_accuracy: 0.1060 - val_loss: 3.1896\n",
      "Epoch 11/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2241 - loss: 2.8876 - val_accuracy: 0.1219 - val_loss: 3.1497\n",
      "Epoch 12/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2310 - loss: 2.8723 - val_accuracy: 0.1828 - val_loss: 3.0419\n",
      "Epoch 13/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2220 - loss: 2.8760 - val_accuracy: 0.1523 - val_loss: 3.1947\n",
      "Epoch 14/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2314 - loss: 2.8707 - val_accuracy: 0.1884 - val_loss: 3.0206\n",
      "Epoch 15/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2319 - loss: 2.8711 - val_accuracy: 0.1662 - val_loss: 3.4583\n",
      "Epoch 16/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2352 - loss: 2.8357 - val_accuracy: 0.1367 - val_loss: 3.2287\n",
      "Epoch 17/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2329 - loss: 2.8829 - val_accuracy: 0.2118 - val_loss: 2.9480\n",
      "Epoch 18/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2407 - loss: 2.8422 - val_accuracy: 0.2135 - val_loss: 2.8759\n",
      "Epoch 19/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2351 - loss: 2.8461 - val_accuracy: 0.1119 - val_loss: 3.4609\n",
      "Epoch 20/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2276 - loss: 2.8518 - val_accuracy: 0.1448 - val_loss: 3.2078\n",
      "Epoch 21/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2346 - loss: 2.8430 - val_accuracy: 0.1952 - val_loss: 2.9637\n",
      "Epoch 22/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2417 - loss: 2.7991 - val_accuracy: 0.0904 - val_loss: 3.4630\n",
      "Epoch 23/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2394 - loss: 2.8123 - val_accuracy: 0.1950 - val_loss: 2.9571\n",
      "Epoch 24/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2433 - loss: 2.8064 - val_accuracy: 0.1808 - val_loss: 3.0245\n",
      "Epoch 25/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2365 - loss: 2.8241 - val_accuracy: 0.1572 - val_loss: 3.1125\n",
      "Epoch 26/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2506 - loss: 2.7997 - val_accuracy: 0.2042 - val_loss: 2.9359\n",
      "Epoch 27/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2400 - loss: 2.7900 - val_accuracy: 0.2091 - val_loss: 2.8508\n",
      "Epoch 28/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.2422 - loss: 2.7678 - val_accuracy: 0.0975 - val_loss: 4.6227\n",
      "Epoch 29/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2338 - loss: 2.8187 - val_accuracy: 0.1679 - val_loss: 3.0214\n",
      "Epoch 30/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2474 - loss: 2.7767 - val_accuracy: 0.2259 - val_loss: 2.8323\n",
      "Epoch 31/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2481 - loss: 2.7590 - val_accuracy: 0.1772 - val_loss: 2.9811\n",
      "Epoch 32/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2466 - loss: 2.7762 - val_accuracy: 0.1735 - val_loss: 3.1464\n",
      "Epoch 33/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2496 - loss: 2.7393 - val_accuracy: 0.0726 - val_loss: 3.3967\n",
      "Epoch 34/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2467 - loss: 2.7544 - val_accuracy: 0.1801 - val_loss: 2.9756\n",
      "Epoch 35/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2554 - loss: 2.7415 - val_accuracy: 0.0824 - val_loss: 3.4767\n",
      "Epoch 36/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2502 - loss: 2.7580 - val_accuracy: 0.2176 - val_loss: 2.7967\n",
      "Epoch 37/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2487 - loss: 2.7392 - val_accuracy: 0.1565 - val_loss: 2.9787\n",
      "Epoch 38/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2498 - loss: 2.7471 - val_accuracy: 0.1709 - val_loss: 3.0180\n",
      "Epoch 39/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2519 - loss: 2.7386 - val_accuracy: 0.1594 - val_loss: 3.0032\n",
      "Epoch 40/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2527 - loss: 2.7234 - val_accuracy: 0.1531 - val_loss: 3.2540\n",
      "Epoch 41/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.2600 - loss: 2.7111 - val_accuracy: 0.1202 - val_loss: 3.1924\n",
      "Epoch 42/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2542 - loss: 2.7326 - val_accuracy: 0.1326 - val_loss: 3.2168\n",
      "Epoch 43/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2542 - loss: 2.7015 - val_accuracy: 0.1801 - val_loss: 2.9191\n",
      "Epoch 44/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2516 - loss: 2.7202 - val_accuracy: 0.1960 - val_loss: 3.1249\n",
      "Epoch 45/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2585 - loss: 2.6960 - val_accuracy: 0.1648 - val_loss: 3.0110\n",
      "Epoch 46/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2425 - loss: 2.7135 - val_accuracy: 0.1903 - val_loss: 2.9958\n",
      "Epoch 47/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2578 - loss: 2.7129 - val_accuracy: 0.1896 - val_loss: 2.9521\n",
      "Epoch 48/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2454 - loss: 2.6947 - val_accuracy: 0.1828 - val_loss: 2.9538\n",
      "Epoch 49/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2529 - loss: 2.7106 - val_accuracy: 0.1029 - val_loss: 3.2790\n",
      "Epoch 50/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2480 - loss: 2.7127 - val_accuracy: 0.1443 - val_loss: 3.0893\n",
      "Epoch 51/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2563 - loss: 2.6961 - val_accuracy: 0.1726 - val_loss: 2.9579\n",
      "Epoch 52/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2524 - loss: 2.6862 - val_accuracy: 0.1682 - val_loss: 3.0050\n",
      "Epoch 53/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2583 - loss: 2.6705 - val_accuracy: 0.1679 - val_loss: 2.9036\n",
      "Epoch 54/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2508 - loss: 2.7034 - val_accuracy: 0.0999 - val_loss: 3.1795\n",
      "Epoch 55/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2568 - loss: 2.6635 - val_accuracy: 0.1662 - val_loss: 2.9940\n",
      "Epoch 56/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2653 - loss: 2.6585 - val_accuracy: 0.1672 - val_loss: 2.9593\n",
      "Epoch 57/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2542 - loss: 2.6635 - val_accuracy: 0.1838 - val_loss: 3.0629\n",
      "Epoch 58/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2559 - loss: 2.6579 - val_accuracy: 0.1436 - val_loss: 3.1923\n",
      "Epoch 59/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2601 - loss: 2.6556 - val_accuracy: 0.2264 - val_loss: 2.8712\n",
      "Epoch 60/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.2544 - loss: 2.6521 - val_accuracy: 0.2201 - val_loss: 2.8928\n",
      "Epoch 61/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2628 - loss: 2.6431 - val_accuracy: 0.1606 - val_loss: 3.0076\n",
      "Epoch 62/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2640 - loss: 2.6320 - val_accuracy: 0.1794 - val_loss: 2.9248\n",
      "Epoch 63/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2618 - loss: 2.6361 - val_accuracy: 0.1972 - val_loss: 2.8946\n",
      "Epoch 64/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2570 - loss: 2.6341 - val_accuracy: 0.1592 - val_loss: 2.9615\n",
      "Epoch 65/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2636 - loss: 2.6309 - val_accuracy: 0.1445 - val_loss: 3.0165\n",
      "Epoch 66/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2518 - loss: 2.6431 - val_accuracy: 0.1869 - val_loss: 3.1332\n",
      "Epoch 67/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2564 - loss: 2.6230 - val_accuracy: 0.1509 - val_loss: 2.9843\n",
      "Epoch 68/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2549 - loss: 2.6590 - val_accuracy: 0.1153 - val_loss: 3.0996\n",
      "Epoch 69/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2417 - loss: 2.6836 - val_accuracy: 0.1423 - val_loss: 2.9229\n",
      "Epoch 70/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2425 - loss: 2.6505 - val_accuracy: 0.2101 - val_loss: 2.8174\n",
      "Epoch 71/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2400 - loss: 2.6619 - val_accuracy: 0.2374 - val_loss: 2.6992\n",
      "Epoch 72/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2511 - loss: 2.6431 - val_accuracy: 0.1107 - val_loss: 3.4528\n",
      "Epoch 73/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2486 - loss: 2.6209 - val_accuracy: 0.2435 - val_loss: 2.6600\n",
      "Epoch 74/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2498 - loss: 2.6299 - val_accuracy: 0.1867 - val_loss: 2.9121\n",
      "Epoch 75/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2551 - loss: 2.6268 - val_accuracy: 0.1833 - val_loss: 2.8268\n",
      "Epoch 76/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2585 - loss: 2.5970 - val_accuracy: 0.1070 - val_loss: 3.1208\n",
      "Epoch 77/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2590 - loss: 2.6024 - val_accuracy: 0.2020 - val_loss: 2.7326\n",
      "Epoch 78/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2561 - loss: 2.6088 - val_accuracy: 0.1443 - val_loss: 2.9057\n",
      "Epoch 79/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2570 - loss: 2.5936 - val_accuracy: 0.2252 - val_loss: 2.7184\n",
      "Epoch 80/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2540 - loss: 2.5987 - val_accuracy: 0.2098 - val_loss: 2.7486\n",
      "Epoch 81/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2589 - loss: 2.6003 - val_accuracy: 0.1253 - val_loss: 2.9755\n",
      "Epoch 82/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2352 - loss: 2.6880 - val_accuracy: 0.1377 - val_loss: 2.9558\n",
      "Epoch 83/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2327 - loss: 2.6583 - val_accuracy: 0.1752 - val_loss: 2.8540\n",
      "Epoch 84/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2362 - loss: 2.6428 - val_accuracy: 0.1372 - val_loss: 3.0038\n",
      "Epoch 85/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2495 - loss: 2.6048 - val_accuracy: 0.1767 - val_loss: 2.8625\n",
      "Epoch 86/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2453 - loss: 2.6247 - val_accuracy: 0.1184 - val_loss: 3.0023\n",
      "Epoch 87/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2537 - loss: 2.6105 - val_accuracy: 0.1328 - val_loss: 3.0546\n",
      "Epoch 88/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2519 - loss: 2.5970 - val_accuracy: 0.1609 - val_loss: 2.8648\n",
      "Epoch 89/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2528 - loss: 2.5928 - val_accuracy: 0.2230 - val_loss: 2.6634\n",
      "Epoch 90/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2473 - loss: 2.6059 - val_accuracy: 0.2486 - val_loss: 2.5763\n",
      "Epoch 91/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2487 - loss: 2.5765 - val_accuracy: 0.1840 - val_loss: 2.8539\n",
      "Epoch 92/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2517 - loss: 2.5921 - val_accuracy: 0.1184 - val_loss: 3.0375\n",
      "Epoch 93/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2446 - loss: 2.6115 - val_accuracy: 0.1365 - val_loss: 3.0461\n",
      "Epoch 94/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.2421 - loss: 2.6070 - val_accuracy: 0.2089 - val_loss: 2.7235\n",
      "Epoch 95/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2439 - loss: 2.5900 - val_accuracy: 0.1903 - val_loss: 2.7858\n",
      "Epoch 96/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.2453 - loss: 2.6035 - val_accuracy: 0.2254 - val_loss: 2.6609\n",
      "Epoch 97/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2411 - loss: 2.5868 - val_accuracy: 0.1211 - val_loss: 3.2865\n",
      "Epoch 98/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.2496 - loss: 2.5844 - val_accuracy: 0.1847 - val_loss: 2.8152\n",
      "Epoch 99/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2495 - loss: 2.5809 - val_accuracy: 0.1484 - val_loss: 2.8940\n",
      "Epoch 100/100\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.2454 - loss: 2.5916 - val_accuracy: 0.1238 - val_loss: 3.0551\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "\tX_train, y_train,\n",
    "\tepochs=100,  # Adjust based on convergence\n",
    "\tbatch_size=32,\n",
    "\tvalidation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0936 - loss: 3.3884 - val_accuracy: 0.1416 - val_loss: 2.8512\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1710 - loss: 2.8447 - val_accuracy: 0.1662 - val_loss: 2.7879\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2227 - loss: 2.6650 - val_accuracy: 0.1765 - val_loss: 2.7888\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2503 - loss: 2.5512 - val_accuracy: 0.1662 - val_loss: 2.7343\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2771 - loss: 2.4517 - val_accuracy: 0.2035 - val_loss: 2.8404\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2786 - loss: 2.4318 - val_accuracy: 0.1857 - val_loss: 2.6019\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2995 - loss: 2.3920 - val_accuracy: 0.2140 - val_loss: 2.7188\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3031 - loss: 2.3436 - val_accuracy: 0.2062 - val_loss: 2.6701\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3133 - loss: 2.3202 - val_accuracy: 0.2208 - val_loss: 2.5368\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3157 - loss: 2.2997 - val_accuracy: 0.2313 - val_loss: 2.6517\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3243 - loss: 2.2596 - val_accuracy: 0.3068 - val_loss: 2.3681\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3396 - loss: 2.2323 - val_accuracy: 0.2445 - val_loss: 2.5132\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3349 - loss: 2.2297 - val_accuracy: 0.2793 - val_loss: 2.3632\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3440 - loss: 2.1984 - val_accuracy: 0.2267 - val_loss: 2.5438\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3476 - loss: 2.1949 - val_accuracy: 0.3042 - val_loss: 2.3645\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3490 - loss: 2.1881 - val_accuracy: 0.2805 - val_loss: 2.3978\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3494 - loss: 2.1749 - val_accuracy: 0.2681 - val_loss: 2.5128\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3419 - loss: 2.1993 - val_accuracy: 0.3159 - val_loss: 2.2487\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3453 - loss: 2.1955 - val_accuracy: 0.2447 - val_loss: 2.5510\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3425 - loss: 2.1877 - val_accuracy: 0.2735 - val_loss: 2.3774\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3453 - loss: 2.1807 - val_accuracy: 0.2145 - val_loss: 2.7576\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3571 - loss: 2.1430 - val_accuracy: 0.2583 - val_loss: 2.5432\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3637 - loss: 2.1315 - val_accuracy: 0.2839 - val_loss: 2.3732\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3582 - loss: 2.1603 - val_accuracy: 0.2152 - val_loss: 2.6801\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3427 - loss: 2.2073 - val_accuracy: 0.1925 - val_loss: 2.7801\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3439 - loss: 2.2033 - val_accuracy: 0.2030 - val_loss: 2.7716\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3364 - loss: 2.2122 - val_accuracy: 0.2072 - val_loss: 2.7984\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3435 - loss: 2.1939 - val_accuracy: 0.2496 - val_loss: 2.4984\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3353 - loss: 2.2162 - val_accuracy: 0.2969 - val_loss: 2.4095\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3483 - loss: 2.1997 - val_accuracy: 0.2079 - val_loss: 2.7060\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3395 - loss: 2.2026 - val_accuracy: 0.2803 - val_loss: 2.4041\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3598 - loss: 2.1445 - val_accuracy: 0.3166 - val_loss: 2.2722\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3651 - loss: 2.1278 - val_accuracy: 0.2340 - val_loss: 2.7189\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3530 - loss: 2.1447 - val_accuracy: 0.2457 - val_loss: 2.5450\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3621 - loss: 2.1339 - val_accuracy: 0.2922 - val_loss: 2.3443\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3650 - loss: 2.1130 - val_accuracy: 0.3293 - val_loss: 2.2176\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3612 - loss: 2.1289 - val_accuracy: 0.3181 - val_loss: 2.2499\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3677 - loss: 2.1108 - val_accuracy: 0.3378 - val_loss: 2.2405\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3612 - loss: 2.1231 - val_accuracy: 0.1972 - val_loss: 3.0043\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3473 - loss: 2.1764 - val_accuracy: 0.2128 - val_loss: 2.7885\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3436 - loss: 2.1669 - val_accuracy: 0.3217 - val_loss: 2.2344\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3525 - loss: 2.1539 - val_accuracy: 0.3022 - val_loss: 2.3345\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3615 - loss: 2.1398 - val_accuracy: 0.3312 - val_loss: 2.1649\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3691 - loss: 2.1137 - val_accuracy: 0.3217 - val_loss: 2.2494\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3646 - loss: 2.1134 - val_accuracy: 0.3276 - val_loss: 2.2225\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3673 - loss: 2.1027 - val_accuracy: 0.1577 - val_loss: 3.1148\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3712 - loss: 2.0982 - val_accuracy: 0.2484 - val_loss: 2.4845\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3549 - loss: 2.1482 - val_accuracy: 0.3488 - val_loss: 2.2073\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3579 - loss: 2.1341 - val_accuracy: 0.2084 - val_loss: 2.7691\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3576 - loss: 2.1455 - val_accuracy: 0.2861 - val_loss: 2.4290\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0943 - loss: 4.9924 - val_accuracy: 0.1297 - val_loss: 3.4767\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1758 - loss: 3.2809 - val_accuracy: 0.1146 - val_loss: 3.1020\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2163 - loss: 2.8381 - val_accuracy: 0.1414 - val_loss: 3.1012\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2264 - loss: 2.6924 - val_accuracy: 0.1921 - val_loss: 2.8307\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2449 - loss: 2.5800 - val_accuracy: 0.1979 - val_loss: 2.8152\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2622 - loss: 2.5123 - val_accuracy: 0.1333 - val_loss: 3.1159\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2605 - loss: 2.5056 - val_accuracy: 0.2488 - val_loss: 2.5035\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2741 - loss: 2.4581 - val_accuracy: 0.2547 - val_loss: 2.5218\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2796 - loss: 2.4378 - val_accuracy: 0.1535 - val_loss: 2.8583\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2852 - loss: 2.4206 - val_accuracy: 0.1928 - val_loss: 2.7422\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2982 - loss: 2.3913 - val_accuracy: 0.1977 - val_loss: 2.8025\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2934 - loss: 2.4086 - val_accuracy: 0.2644 - val_loss: 2.5012\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3026 - loss: 2.3646 - val_accuracy: 0.2547 - val_loss: 2.4848\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2975 - loss: 2.3873 - val_accuracy: 0.1287 - val_loss: 3.1396\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2908 - loss: 2.4042 - val_accuracy: 0.1465 - val_loss: 2.9742\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2930 - loss: 2.3811 - val_accuracy: 0.1765 - val_loss: 2.8423\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2856 - loss: 2.4091 - val_accuracy: 0.1933 - val_loss: 2.6433\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2939 - loss: 2.3879 - val_accuracy: 0.1891 - val_loss: 2.6958\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2950 - loss: 2.3978 - val_accuracy: 0.1864 - val_loss: 2.8646\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2926 - loss: 2.3853 - val_accuracy: 0.1518 - val_loss: 3.2816\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3008 - loss: 2.3763 - val_accuracy: 0.2710 - val_loss: 2.4795\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3131 - loss: 2.3574 - val_accuracy: 0.1387 - val_loss: 3.0858\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3112 - loss: 2.3470 - val_accuracy: 0.1916 - val_loss: 2.7431\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3037 - loss: 2.3618 - val_accuracy: 0.2737 - val_loss: 2.4256\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3006 - loss: 2.3724 - val_accuracy: 0.2505 - val_loss: 2.5956\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2989 - loss: 2.3816 - val_accuracy: 0.3022 - val_loss: 2.3949\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3063 - loss: 2.3651 - val_accuracy: 0.2308 - val_loss: 2.5789\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3092 - loss: 2.3550 - val_accuracy: 0.2059 - val_loss: 2.9395\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3032 - loss: 2.3595 - val_accuracy: 0.2508 - val_loss: 2.4954\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3043 - loss: 2.3569 - val_accuracy: 0.2976 - val_loss: 2.3592\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3141 - loss: 2.3459 - val_accuracy: 0.1309 - val_loss: 3.3204\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3043 - loss: 2.3679 - val_accuracy: 0.2484 - val_loss: 2.5189\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2885 - loss: 2.3979 - val_accuracy: 0.1726 - val_loss: 3.0478\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2915 - loss: 2.3932 - val_accuracy: 0.2235 - val_loss: 2.6655\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2933 - loss: 2.3794 - val_accuracy: 0.2552 - val_loss: 2.5104\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3083 - loss: 2.3476 - val_accuracy: 0.2225 - val_loss: 2.7001\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3020 - loss: 2.3599 - val_accuracy: 0.1813 - val_loss: 2.7507\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2916 - loss: 2.3713 - val_accuracy: 0.2301 - val_loss: 2.5904\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2867 - loss: 2.3843 - val_accuracy: 0.2715 - val_loss: 2.4330\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2893 - loss: 2.3919 - val_accuracy: 0.2447 - val_loss: 2.6715\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2876 - loss: 2.3774 - val_accuracy: 0.1882 - val_loss: 2.6792\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2893 - loss: 2.3885 - val_accuracy: 0.2084 - val_loss: 2.8376\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2854 - loss: 2.3740 - val_accuracy: 0.2513 - val_loss: 2.4820\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2951 - loss: 2.3602 - val_accuracy: 0.2598 - val_loss: 2.4334\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2965 - loss: 2.3409 - val_accuracy: 0.1645 - val_loss: 2.9098\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2967 - loss: 2.3497 - val_accuracy: 0.2861 - val_loss: 2.3699\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2965 - loss: 2.3585 - val_accuracy: 0.1499 - val_loss: 3.0316\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2926 - loss: 2.3645 - val_accuracy: 0.2471 - val_loss: 2.4780\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2972 - loss: 2.3431 - val_accuracy: 0.1935 - val_loss: 2.7462\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2972 - loss: 2.3523 - val_accuracy: 0.2264 - val_loss: 2.7373\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0833 - loss: 3.5050 - val_accuracy: 0.1314 - val_loss: 2.8787\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1410 - loss: 2.9240 - val_accuracy: 0.2035 - val_loss: 2.7198\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1811 - loss: 2.7426 - val_accuracy: 0.1882 - val_loss: 2.7048\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2132 - loss: 2.6298 - val_accuracy: 0.1701 - val_loss: 2.6628\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2403 - loss: 2.5521 - val_accuracy: 0.1655 - val_loss: 2.6530\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2429 - loss: 2.5168 - val_accuracy: 0.2481 - val_loss: 2.5162\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2636 - loss: 2.4731 - val_accuracy: 0.3022 - val_loss: 2.3974\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2812 - loss: 2.4299 - val_accuracy: 0.2393 - val_loss: 2.5357\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2790 - loss: 2.4112 - val_accuracy: 0.2296 - val_loss: 2.5538\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2970 - loss: 2.3839 - val_accuracy: 0.2839 - val_loss: 2.4221\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2898 - loss: 2.3657 - val_accuracy: 0.2410 - val_loss: 2.5230\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2860 - loss: 2.3770 - val_accuracy: 0.2640 - val_loss: 2.4648\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2888 - loss: 2.3609 - val_accuracy: 0.2445 - val_loss: 2.4741\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2973 - loss: 2.3416 - val_accuracy: 0.1426 - val_loss: 2.8328\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3108 - loss: 2.3136 - val_accuracy: 0.2410 - val_loss: 2.4764\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3095 - loss: 2.3099 - val_accuracy: 0.2418 - val_loss: 2.5565\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3099 - loss: 2.3215 - val_accuracy: 0.1999 - val_loss: 2.7597\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3176 - loss: 2.3037 - val_accuracy: 0.2008 - val_loss: 2.6561\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3134 - loss: 2.2987 - val_accuracy: 0.2350 - val_loss: 2.5723\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3130 - loss: 2.3003 - val_accuracy: 0.2988 - val_loss: 2.2982\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3111 - loss: 2.2957 - val_accuracy: 0.3042 - val_loss: 2.2983\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3120 - loss: 2.2918 - val_accuracy: 0.2900 - val_loss: 2.3313\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3099 - loss: 2.2814 - val_accuracy: 0.2169 - val_loss: 2.6268\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3242 - loss: 2.2684 - val_accuracy: 0.3217 - val_loss: 2.2474\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3141 - loss: 2.2828 - val_accuracy: 0.2908 - val_loss: 2.3743\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3232 - loss: 2.2578 - val_accuracy: 0.2559 - val_loss: 2.4723\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3088 - loss: 2.2994 - val_accuracy: 0.1942 - val_loss: 2.6258\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3143 - loss: 2.2881 - val_accuracy: 0.2988 - val_loss: 2.4104\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3083 - loss: 2.2961 - val_accuracy: 0.1506 - val_loss: 3.0610\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3151 - loss: 2.2744 - val_accuracy: 0.2654 - val_loss: 2.3927\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3147 - loss: 2.2568 - val_accuracy: 0.2293 - val_loss: 2.6202\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3072 - loss: 2.2788 - val_accuracy: 0.2644 - val_loss: 2.4591\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3241 - loss: 2.2554 - val_accuracy: 0.2620 - val_loss: 2.4202\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3218 - loss: 2.2329 - val_accuracy: 0.2413 - val_loss: 2.6063\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3281 - loss: 2.2245 - val_accuracy: 0.2754 - val_loss: 2.3612\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3207 - loss: 2.2575 - val_accuracy: 0.3195 - val_loss: 2.2817\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3190 - loss: 2.2768 - val_accuracy: 0.2813 - val_loss: 2.4006\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3007 - loss: 2.3004 - val_accuracy: 0.3266 - val_loss: 2.2642\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3127 - loss: 2.2787 - val_accuracy: 0.2013 - val_loss: 2.7404\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3159 - loss: 2.2641 - val_accuracy: 0.3181 - val_loss: 2.2843\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3163 - loss: 2.2524 - val_accuracy: 0.2854 - val_loss: 2.3172\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3273 - loss: 2.2320 - val_accuracy: 0.2284 - val_loss: 2.6041\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3123 - loss: 2.2711 - val_accuracy: 0.3283 - val_loss: 2.2997\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3179 - loss: 2.2572 - val_accuracy: 0.2413 - val_loss: 2.4937\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3182 - loss: 2.2622 - val_accuracy: 0.2040 - val_loss: 2.7270\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3158 - loss: 2.2705 - val_accuracy: 0.2471 - val_loss: 2.4410\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3155 - loss: 2.2483 - val_accuracy: 0.2410 - val_loss: 2.4348\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3103 - loss: 2.2630 - val_accuracy: 0.2430 - val_loss: 2.5052\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3183 - loss: 2.2462 - val_accuracy: 0.2586 - val_loss: 2.3842\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3165 - loss: 2.2510 - val_accuracy: 0.2296 - val_loss: 2.5729\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0851 - loss: 5.2497 - val_accuracy: 0.1111 - val_loss: 3.5457\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1470 - loss: 3.3989 - val_accuracy: 0.0951 - val_loss: 3.1199\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1860 - loss: 2.9091 - val_accuracy: 0.1860 - val_loss: 2.7857\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2159 - loss: 2.7162 - val_accuracy: 0.1460 - val_loss: 2.9330\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2306 - loss: 2.6234 - val_accuracy: 0.1752 - val_loss: 2.7271\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2348 - loss: 2.5985 - val_accuracy: 0.1867 - val_loss: 2.7052\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2484 - loss: 2.5550 - val_accuracy: 0.2245 - val_loss: 2.6034\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2491 - loss: 2.5483 - val_accuracy: 0.1908 - val_loss: 2.7666\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2629 - loss: 2.5230 - val_accuracy: 0.1913 - val_loss: 2.7188\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2592 - loss: 2.5089 - val_accuracy: 0.1667 - val_loss: 2.7047\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2620 - loss: 2.5022 - val_accuracy: 0.1197 - val_loss: 3.0620\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2596 - loss: 2.5142 - val_accuracy: 0.1889 - val_loss: 2.8570\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2659 - loss: 2.4965 - val_accuracy: 0.1231 - val_loss: 2.9951\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2565 - loss: 2.5075 - val_accuracy: 0.1358 - val_loss: 2.9800\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2610 - loss: 2.5028 - val_accuracy: 0.2569 - val_loss: 2.5069\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2664 - loss: 2.4704 - val_accuracy: 0.1730 - val_loss: 2.8257\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2702 - loss: 2.4773 - val_accuracy: 0.1146 - val_loss: 3.2095\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2560 - loss: 2.4980 - val_accuracy: 0.2413 - val_loss: 2.5286\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2712 - loss: 2.4653 - val_accuracy: 0.2267 - val_loss: 2.5802\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2633 - loss: 2.4735 - val_accuracy: 0.1745 - val_loss: 3.0265\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2672 - loss: 2.4799 - val_accuracy: 0.2308 - val_loss: 2.5961\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2655 - loss: 2.4743 - val_accuracy: 0.2608 - val_loss: 2.5088\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2698 - loss: 2.4568 - val_accuracy: 0.1538 - val_loss: 2.9730\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2555 - loss: 2.4955 - val_accuracy: 0.1655 - val_loss: 3.0152\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2672 - loss: 2.4682 - val_accuracy: 0.1672 - val_loss: 3.0965\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2723 - loss: 2.4570 - val_accuracy: 0.1774 - val_loss: 2.6639\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2709 - loss: 2.4620 - val_accuracy: 0.2247 - val_loss: 2.6107\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2675 - loss: 2.4615 - val_accuracy: 0.1092 - val_loss: 3.2983\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2708 - loss: 2.4589 - val_accuracy: 0.1684 - val_loss: 2.7344\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2740 - loss: 2.4374 - val_accuracy: 0.2023 - val_loss: 2.7008\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2711 - loss: 2.4398 - val_accuracy: 0.2554 - val_loss: 2.5090\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2799 - loss: 2.4273 - val_accuracy: 0.2067 - val_loss: 2.7523\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2670 - loss: 2.4565 - val_accuracy: 0.1548 - val_loss: 2.8587\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2678 - loss: 2.4722 - val_accuracy: 0.2262 - val_loss: 2.5610\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2686 - loss: 2.4504 - val_accuracy: 0.2130 - val_loss: 2.5803\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2682 - loss: 2.4566 - val_accuracy: 0.2430 - val_loss: 2.5185\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2754 - loss: 2.4365 - val_accuracy: 0.2025 - val_loss: 2.6385\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2699 - loss: 2.4415 - val_accuracy: 0.2688 - val_loss: 2.4700\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2744 - loss: 2.4516 - val_accuracy: 0.2281 - val_loss: 2.5447\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2759 - loss: 2.4390 - val_accuracy: 0.2264 - val_loss: 2.5985\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2650 - loss: 2.4509 - val_accuracy: 0.1806 - val_loss: 2.6518\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2656 - loss: 2.4591 - val_accuracy: 0.2508 - val_loss: 2.5362\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2768 - loss: 2.4289 - val_accuracy: 0.2381 - val_loss: 2.5184\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2615 - loss: 2.4616 - val_accuracy: 0.2067 - val_loss: 2.6977\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2635 - loss: 2.4651 - val_accuracy: 0.2484 - val_loss: 2.4738\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2646 - loss: 2.4492 - val_accuracy: 0.1670 - val_loss: 2.7482\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2704 - loss: 2.4412 - val_accuracy: 0.2459 - val_loss: 2.5458\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2676 - loss: 2.4379 - val_accuracy: 0.1981 - val_loss: 2.7781\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2744 - loss: 2.4450 - val_accuracy: 0.2583 - val_loss: 2.4691\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2696 - loss: 2.4355 - val_accuracy: 0.1467 - val_loss: 2.7712\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.0909 - loss: 3.6766 - val_accuracy: 0.1484 - val_loss: 3.0788\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1650 - loss: 3.0582 - val_accuracy: 0.1925 - val_loss: 2.8963\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2289 - loss: 2.8170 - val_accuracy: 0.2006 - val_loss: 2.8146\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2466 - loss: 2.6864 - val_accuracy: 0.2113 - val_loss: 2.8219\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2742 - loss: 2.5667 - val_accuracy: 0.2074 - val_loss: 2.7311\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2898 - loss: 2.4999 - val_accuracy: 0.2462 - val_loss: 2.6253\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2995 - loss: 2.4525 - val_accuracy: 0.1562 - val_loss: 2.7903\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3127 - loss: 2.3851 - val_accuracy: 0.2403 - val_loss: 2.5962\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3371 - loss: 2.3260 - val_accuracy: 0.1879 - val_loss: 2.8413\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3363 - loss: 2.3157 - val_accuracy: 0.2781 - val_loss: 2.5140\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3333 - loss: 2.2893 - val_accuracy: 0.2284 - val_loss: 2.6844\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3544 - loss: 2.2454 - val_accuracy: 0.3558 - val_loss: 2.2593\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3553 - loss: 2.2290 - val_accuracy: 0.2493 - val_loss: 2.5500\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3476 - loss: 2.2546 - val_accuracy: 0.2047 - val_loss: 2.7988\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3481 - loss: 2.2598 - val_accuracy: 0.3066 - val_loss: 2.3783\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3591 - loss: 2.2361 - val_accuracy: 0.3385 - val_loss: 2.2934\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3667 - loss: 2.2092 - val_accuracy: 0.3251 - val_loss: 2.3291\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3584 - loss: 2.2056 - val_accuracy: 0.2540 - val_loss: 2.6294\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3697 - loss: 2.1771 - val_accuracy: 0.3034 - val_loss: 2.4133\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3621 - loss: 2.1880 - val_accuracy: 0.2808 - val_loss: 2.4673\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3671 - loss: 2.1891 - val_accuracy: 0.3144 - val_loss: 2.3610\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3708 - loss: 2.1736 - val_accuracy: 0.1913 - val_loss: 2.8748\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3582 - loss: 2.1923 - val_accuracy: 0.2235 - val_loss: 2.7887\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3712 - loss: 2.1662 - val_accuracy: 0.2913 - val_loss: 2.3957\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3617 - loss: 2.1995 - val_accuracy: 0.3117 - val_loss: 2.3613\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3621 - loss: 2.1723 - val_accuracy: 0.2018 - val_loss: 2.7044\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3715 - loss: 2.1630 - val_accuracy: 0.2803 - val_loss: 2.3857\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3659 - loss: 2.1701 - val_accuracy: 0.3083 - val_loss: 2.3502\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3738 - loss: 2.1541 - val_accuracy: 0.2518 - val_loss: 2.6135\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3653 - loss: 2.1686 - val_accuracy: 0.3161 - val_loss: 2.3494\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3666 - loss: 2.1674 - val_accuracy: 0.3042 - val_loss: 2.3537\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3730 - loss: 2.1500 - val_accuracy: 0.2055 - val_loss: 2.9300\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3722 - loss: 2.1600 - val_accuracy: 0.2189 - val_loss: 2.5736\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3782 - loss: 2.1379 - val_accuracy: 0.3727 - val_loss: 2.1818\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3785 - loss: 2.1247 - val_accuracy: 0.3595 - val_loss: 2.1838\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3695 - loss: 2.1588 - val_accuracy: 0.3105 - val_loss: 2.3553\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3793 - loss: 2.1141 - val_accuracy: 0.3517 - val_loss: 2.2040\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3696 - loss: 2.1315 - val_accuracy: 0.2917 - val_loss: 2.4281\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3640 - loss: 2.1547 - val_accuracy: 0.3549 - val_loss: 2.2042\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3650 - loss: 2.1616 - val_accuracy: 0.2886 - val_loss: 2.5022\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3768 - loss: 2.1283 - val_accuracy: 0.2981 - val_loss: 2.3595\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3796 - loss: 2.1233 - val_accuracy: 0.2627 - val_loss: 2.5435\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3686 - loss: 2.1322 - val_accuracy: 0.3185 - val_loss: 2.2712\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3777 - loss: 2.1259 - val_accuracy: 0.3700 - val_loss: 2.1887\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3716 - loss: 2.1470 - val_accuracy: 0.3010 - val_loss: 2.3788\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3780 - loss: 2.1445 - val_accuracy: 0.3495 - val_loss: 2.1552\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3650 - loss: 2.1587 - val_accuracy: 0.2172 - val_loss: 2.6921\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3768 - loss: 2.1393 - val_accuracy: 0.3317 - val_loss: 2.2463\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3556 - loss: 2.2025 - val_accuracy: 0.2973 - val_loss: 2.3932\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3550 - loss: 2.1974 - val_accuracy: 0.3285 - val_loss: 2.2754\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.0875 - loss: 6.8926 - val_accuracy: 0.1526 - val_loss: 4.2890\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1645 - loss: 3.9526 - val_accuracy: 0.1448 - val_loss: 3.3031\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2038 - loss: 3.1043 - val_accuracy: 0.1721 - val_loss: 2.9669\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2324 - loss: 2.7978 - val_accuracy: 0.1796 - val_loss: 2.8182\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2393 - loss: 2.6703 - val_accuracy: 0.1418 - val_loss: 2.9124\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2521 - loss: 2.6218 - val_accuracy: 0.1645 - val_loss: 2.7585\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2556 - loss: 2.5964 - val_accuracy: 0.1562 - val_loss: 3.0035\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2667 - loss: 2.5410 - val_accuracy: 0.1584 - val_loss: 2.9038\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2694 - loss: 2.5306 - val_accuracy: 0.1667 - val_loss: 2.8032\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2762 - loss: 2.5066 - val_accuracy: 0.1565 - val_loss: 2.9252\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2810 - loss: 2.5116 - val_accuracy: 0.2705 - val_loss: 2.5135\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2871 - loss: 2.4878 - val_accuracy: 0.2252 - val_loss: 2.6554\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2840 - loss: 2.4933 - val_accuracy: 0.1791 - val_loss: 2.8599\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2881 - loss: 2.4666 - val_accuracy: 0.1423 - val_loss: 3.0451\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2842 - loss: 2.4908 - val_accuracy: 0.1484 - val_loss: 2.9034\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2845 - loss: 2.4684 - val_accuracy: 0.2196 - val_loss: 2.7486\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2916 - loss: 2.4640 - val_accuracy: 0.1777 - val_loss: 2.8721\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2908 - loss: 2.4674 - val_accuracy: 0.1433 - val_loss: 2.8606\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2973 - loss: 2.4542 - val_accuracy: 0.2293 - val_loss: 2.6526\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2977 - loss: 2.4406 - val_accuracy: 0.2047 - val_loss: 2.8291\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2956 - loss: 2.4434 - val_accuracy: 0.2442 - val_loss: 2.5617\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3038 - loss: 2.4260 - val_accuracy: 0.1877 - val_loss: 2.7461\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2994 - loss: 2.4268 - val_accuracy: 0.2311 - val_loss: 2.6025\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3030 - loss: 2.4368 - val_accuracy: 0.2627 - val_loss: 2.5443\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2902 - loss: 2.4515 - val_accuracy: 0.2352 - val_loss: 2.6035\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2959 - loss: 2.4510 - val_accuracy: 0.1960 - val_loss: 2.7860\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2918 - loss: 2.4421 - val_accuracy: 0.2720 - val_loss: 2.4583\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2846 - loss: 2.4615 - val_accuracy: 0.2332 - val_loss: 2.7081\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2957 - loss: 2.4440 - val_accuracy: 0.1779 - val_loss: 2.7959\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2979 - loss: 2.4321 - val_accuracy: 0.2335 - val_loss: 2.5975\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2986 - loss: 2.4375 - val_accuracy: 0.2223 - val_loss: 2.6667\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2860 - loss: 2.4610 - val_accuracy: 0.3076 - val_loss: 2.4140\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2812 - loss: 2.4644 - val_accuracy: 0.2669 - val_loss: 2.5280\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2863 - loss: 2.4573 - val_accuracy: 0.1996 - val_loss: 2.6787\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2950 - loss: 2.4432 - val_accuracy: 0.1916 - val_loss: 2.7308\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2973 - loss: 2.4237 - val_accuracy: 0.1267 - val_loss: 3.0584\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2933 - loss: 2.4306 - val_accuracy: 0.1825 - val_loss: 2.7960\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2948 - loss: 2.4222 - val_accuracy: 0.2274 - val_loss: 2.6405\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2953 - loss: 2.4189 - val_accuracy: 0.2615 - val_loss: 2.5206\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2847 - loss: 2.4490 - val_accuracy: 0.1350 - val_loss: 3.0262\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2889 - loss: 2.4295 - val_accuracy: 0.1733 - val_loss: 3.0932\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2966 - loss: 2.4311 - val_accuracy: 0.1691 - val_loss: 2.9249\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2919 - loss: 2.4283 - val_accuracy: 0.2281 - val_loss: 2.5569\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3055 - loss: 2.4006 - val_accuracy: 0.1514 - val_loss: 2.9335\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2884 - loss: 2.4334 - val_accuracy: 0.1599 - val_loss: 2.8452\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2984 - loss: 2.4113 - val_accuracy: 0.2442 - val_loss: 2.6468\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2887 - loss: 2.4518 - val_accuracy: 0.2211 - val_loss: 2.6182\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2751 - loss: 2.4663 - val_accuracy: 0.1457 - val_loss: 2.9142\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2903 - loss: 2.4460 - val_accuracy: 0.2237 - val_loss: 2.6816\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2827 - loss: 2.4359 - val_accuracy: 0.1104 - val_loss: 3.0987\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.0828 - loss: 3.8218 - val_accuracy: 0.1155 - val_loss: 3.1101\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1305 - loss: 3.1568 - val_accuracy: 0.1913 - val_loss: 2.9126\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1739 - loss: 2.9420 - val_accuracy: 0.2220 - val_loss: 2.7895\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2008 - loss: 2.8209 - val_accuracy: 0.1640 - val_loss: 2.8127\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2319 - loss: 2.6984 - val_accuracy: 0.2064 - val_loss: 2.7783\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2427 - loss: 2.6483 - val_accuracy: 0.1903 - val_loss: 2.8050\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2525 - loss: 2.5800 - val_accuracy: 0.1794 - val_loss: 2.8533\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2658 - loss: 2.5213 - val_accuracy: 0.1670 - val_loss: 2.8559\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2824 - loss: 2.4807 - val_accuracy: 0.2191 - val_loss: 2.6296\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2829 - loss: 2.4437 - val_accuracy: 0.1545 - val_loss: 2.9517\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2832 - loss: 2.4411 - val_accuracy: 0.2089 - val_loss: 2.6901\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2917 - loss: 2.4092 - val_accuracy: 0.2718 - val_loss: 2.4510\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3049 - loss: 2.3789 - val_accuracy: 0.1704 - val_loss: 2.7826\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2971 - loss: 2.3876 - val_accuracy: 0.2364 - val_loss: 2.4932\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2980 - loss: 2.3704 - val_accuracy: 0.2683 - val_loss: 2.4405\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3142 - loss: 2.3522 - val_accuracy: 0.2791 - val_loss: 2.4262\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3131 - loss: 2.3354 - val_accuracy: 0.2727 - val_loss: 2.4602\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3136 - loss: 2.3306 - val_accuracy: 0.1701 - val_loss: 2.7661\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3129 - loss: 2.3342 - val_accuracy: 0.1694 - val_loss: 2.7293\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3001 - loss: 2.3801 - val_accuracy: 0.2642 - val_loss: 2.5149\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3079 - loss: 2.3346 - val_accuracy: 0.2186 - val_loss: 2.5601\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3135 - loss: 2.3341 - val_accuracy: 0.3139 - val_loss: 2.3072\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3183 - loss: 2.2967 - val_accuracy: 0.2920 - val_loss: 2.3616\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3165 - loss: 2.3271 - val_accuracy: 0.2886 - val_loss: 2.3547\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3225 - loss: 2.3087 - val_accuracy: 0.3478 - val_loss: 2.2410\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3185 - loss: 2.3086 - val_accuracy: 0.2713 - val_loss: 2.4538\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3153 - loss: 2.3200 - val_accuracy: 0.2947 - val_loss: 2.3990\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3186 - loss: 2.3112 - val_accuracy: 0.2849 - val_loss: 2.4140\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3174 - loss: 2.3203 - val_accuracy: 0.2622 - val_loss: 2.5022\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3136 - loss: 2.3149 - val_accuracy: 0.3020 - val_loss: 2.3671\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3183 - loss: 2.3060 - val_accuracy: 0.2605 - val_loss: 2.4793\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3165 - loss: 2.2924 - val_accuracy: 0.2676 - val_loss: 2.4379\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3161 - loss: 2.3013 - val_accuracy: 0.2659 - val_loss: 2.4155\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3193 - loss: 2.2973 - val_accuracy: 0.2549 - val_loss: 2.4657\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3156 - loss: 2.3038 - val_accuracy: 0.3142 - val_loss: 2.2988\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3317 - loss: 2.2743 - val_accuracy: 0.2908 - val_loss: 2.3744\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3170 - loss: 2.2995 - val_accuracy: 0.2374 - val_loss: 2.5166\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3184 - loss: 2.2863 - val_accuracy: 0.2601 - val_loss: 2.4525\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3230 - loss: 2.2796 - val_accuracy: 0.1596 - val_loss: 2.8328\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3253 - loss: 2.2846 - val_accuracy: 0.3149 - val_loss: 2.3513\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3227 - loss: 2.2898 - val_accuracy: 0.3098 - val_loss: 2.2861\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3140 - loss: 2.2905 - val_accuracy: 0.2530 - val_loss: 2.4311\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3269 - loss: 2.2758 - val_accuracy: 0.2666 - val_loss: 2.4375\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3267 - loss: 2.2695 - val_accuracy: 0.2927 - val_loss: 2.3546\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3242 - loss: 2.2732 - val_accuracy: 0.2939 - val_loss: 2.3505\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3236 - loss: 2.2828 - val_accuracy: 0.1991 - val_loss: 2.6893\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3258 - loss: 2.2834 - val_accuracy: 0.3415 - val_loss: 2.2111\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3273 - loss: 2.2774 - val_accuracy: 0.2008 - val_loss: 2.6774\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3292 - loss: 2.2581 - val_accuracy: 0.1830 - val_loss: 2.7797\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3282 - loss: 2.2458 - val_accuracy: 0.2652 - val_loss: 2.3824\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.0841 - loss: 7.2760 - val_accuracy: 0.1131 - val_loss: 4.5487\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1254 - loss: 4.2446 - val_accuracy: 0.1584 - val_loss: 3.3737\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1681 - loss: 3.2526 - val_accuracy: 0.1743 - val_loss: 2.9799\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1914 - loss: 2.8903 - val_accuracy: 0.1601 - val_loss: 2.8498\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2054 - loss: 2.7512 - val_accuracy: 0.1382 - val_loss: 2.8711\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2154 - loss: 2.6931 - val_accuracy: 0.1813 - val_loss: 2.7506\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2218 - loss: 2.6652 - val_accuracy: 0.1962 - val_loss: 2.8040\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2393 - loss: 2.6362 - val_accuracy: 0.1204 - val_loss: 2.8893\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2331 - loss: 2.6358 - val_accuracy: 0.1723 - val_loss: 2.8522\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2287 - loss: 2.6248 - val_accuracy: 0.2510 - val_loss: 2.5938\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2407 - loss: 2.6021 - val_accuracy: 0.2062 - val_loss: 2.7059\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2413 - loss: 2.6010 - val_accuracy: 0.0760 - val_loss: 3.1155\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2469 - loss: 2.5884 - val_accuracy: 0.1326 - val_loss: 2.9633\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2532 - loss: 2.5814 - val_accuracy: 0.1933 - val_loss: 2.7775\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2525 - loss: 2.5676 - val_accuracy: 0.2286 - val_loss: 2.6323\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2514 - loss: 2.5779 - val_accuracy: 0.2259 - val_loss: 2.6355\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2537 - loss: 2.5574 - val_accuracy: 0.1657 - val_loss: 2.9076\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2630 - loss: 2.5459 - val_accuracy: 0.2464 - val_loss: 2.5852\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2571 - loss: 2.5439 - val_accuracy: 0.2045 - val_loss: 2.6871\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2617 - loss: 2.5399 - val_accuracy: 0.1745 - val_loss: 2.7645\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2684 - loss: 2.5407 - val_accuracy: 0.1706 - val_loss: 2.8117\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2634 - loss: 2.5499 - val_accuracy: 0.1506 - val_loss: 2.8826\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2580 - loss: 2.5596 - val_accuracy: 0.1367 - val_loss: 2.9301\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2627 - loss: 2.5476 - val_accuracy: 0.2101 - val_loss: 2.7257\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2676 - loss: 2.5196 - val_accuracy: 0.1665 - val_loss: 2.8415\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2548 - loss: 2.5472 - val_accuracy: 0.1248 - val_loss: 3.2031\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2590 - loss: 2.5528 - val_accuracy: 0.2432 - val_loss: 2.5583\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2602 - loss: 2.5497 - val_accuracy: 0.1750 - val_loss: 2.7816\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2594 - loss: 2.5378 - val_accuracy: 0.2028 - val_loss: 2.6868\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2595 - loss: 2.5416 - val_accuracy: 0.1158 - val_loss: 3.0305\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2566 - loss: 2.5365 - val_accuracy: 0.2274 - val_loss: 2.6068\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2566 - loss: 2.5434 - val_accuracy: 0.2669 - val_loss: 2.5518\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2552 - loss: 2.5335 - val_accuracy: 0.2030 - val_loss: 2.6408\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2466 - loss: 2.5512 - val_accuracy: 0.2059 - val_loss: 2.6717\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2555 - loss: 2.5363 - val_accuracy: 0.2449 - val_loss: 2.5355\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2503 - loss: 2.5607 - val_accuracy: 0.2098 - val_loss: 2.6706\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2448 - loss: 2.5636 - val_accuracy: 0.2013 - val_loss: 2.6316\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2448 - loss: 2.5434 - val_accuracy: 0.2259 - val_loss: 2.6521\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2490 - loss: 2.5523 - val_accuracy: 0.1601 - val_loss: 2.7861\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2542 - loss: 2.5211 - val_accuracy: 0.2523 - val_loss: 2.5851\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2604 - loss: 2.5092 - val_accuracy: 0.1843 - val_loss: 2.7242\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2591 - loss: 2.5186 - val_accuracy: 0.1584 - val_loss: 2.8841\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2442 - loss: 2.5436 - val_accuracy: 0.1911 - val_loss: 2.6521\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2509 - loss: 2.5388 - val_accuracy: 0.2488 - val_loss: 2.5223\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2622 - loss: 2.5110 - val_accuracy: 0.1340 - val_loss: 3.0097\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2529 - loss: 2.5228 - val_accuracy: 0.0926 - val_loss: 3.1295\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2547 - loss: 2.5132 - val_accuracy: 0.2362 - val_loss: 2.5474\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2614 - loss: 2.5116 - val_accuracy: 0.1255 - val_loss: 2.9244\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2470 - loss: 2.5410 - val_accuracy: 0.2023 - val_loss: 2.6754\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2594 - loss: 2.5207 - val_accuracy: 0.1947 - val_loss: 2.7466\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0797 - loss: 4.1534 - val_accuracy: 0.1382 - val_loss: 3.4270\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1430 - loss: 3.4351 - val_accuracy: 0.1709 - val_loss: 3.2713\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2067 - loss: 3.1387 - val_accuracy: 0.2040 - val_loss: 3.0627\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2410 - loss: 2.9242 - val_accuracy: 0.2508 - val_loss: 2.8445\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2695 - loss: 2.7741 - val_accuracy: 0.2142 - val_loss: 2.8638\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2970 - loss: 2.6525 - val_accuracy: 0.1879 - val_loss: 2.8853\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3029 - loss: 2.5754 - val_accuracy: 0.3027 - val_loss: 2.5668\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3268 - loss: 2.4967 - val_accuracy: 0.1562 - val_loss: 3.0329\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3336 - loss: 2.4505 - val_accuracy: 0.2484 - val_loss: 2.7503\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3445 - loss: 2.4072 - val_accuracy: 0.3171 - val_loss: 2.4720\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3577 - loss: 2.3673 - val_accuracy: 0.2518 - val_loss: 2.6753\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3671 - loss: 2.3427 - val_accuracy: 0.2135 - val_loss: 2.8084\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3752 - loss: 2.3048 - val_accuracy: 0.1994 - val_loss: 2.8977\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3781 - loss: 2.3079 - val_accuracy: 0.2844 - val_loss: 2.6304\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3652 - loss: 2.3302 - val_accuracy: 0.3424 - val_loss: 2.4546\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3839 - loss: 2.2902 - val_accuracy: 0.2574 - val_loss: 2.6785\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3826 - loss: 2.2775 - val_accuracy: 0.2954 - val_loss: 2.5980\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3973 - loss: 2.2410 - val_accuracy: 0.2805 - val_loss: 2.6601\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3967 - loss: 2.2396 - val_accuracy: 0.2798 - val_loss: 2.5847\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3945 - loss: 2.2419 - val_accuracy: 0.2425 - val_loss: 2.7573\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3912 - loss: 2.2596 - val_accuracy: 0.3388 - val_loss: 2.4645\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3976 - loss: 2.2489 - val_accuracy: 0.3527 - val_loss: 2.3691\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3987 - loss: 2.2335 - val_accuracy: 0.3483 - val_loss: 2.3755\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4023 - loss: 2.2195 - val_accuracy: 0.2464 - val_loss: 2.7040\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4051 - loss: 2.1922 - val_accuracy: 0.2225 - val_loss: 2.9219\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3949 - loss: 2.2389 - val_accuracy: 0.1947 - val_loss: 2.8253\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3888 - loss: 2.2301 - val_accuracy: 0.3471 - val_loss: 2.3888\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4055 - loss: 2.1992 - val_accuracy: 0.3176 - val_loss: 2.4605\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3987 - loss: 2.2021 - val_accuracy: 0.3029 - val_loss: 2.5622\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4091 - loss: 2.1923 - val_accuracy: 0.3561 - val_loss: 2.3261\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4097 - loss: 2.1682 - val_accuracy: 0.3271 - val_loss: 2.4651\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4014 - loss: 2.1738 - val_accuracy: 0.2427 - val_loss: 2.7307\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4119 - loss: 2.1505 - val_accuracy: 0.3295 - val_loss: 2.4832\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4079 - loss: 2.1783 - val_accuracy: 0.1282 - val_loss: 3.2272\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3877 - loss: 2.2202 - val_accuracy: 0.2452 - val_loss: 2.8001\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4032 - loss: 2.1882 - val_accuracy: 0.3051 - val_loss: 2.4678\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4089 - loss: 2.1605 - val_accuracy: 0.3432 - val_loss: 2.3439\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4027 - loss: 2.1898 - val_accuracy: 0.2978 - val_loss: 2.5683\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3923 - loss: 2.2074 - val_accuracy: 0.2583 - val_loss: 2.7125\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3936 - loss: 2.2260 - val_accuracy: 0.3051 - val_loss: 2.5163\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3920 - loss: 2.2251 - val_accuracy: 0.2864 - val_loss: 2.6105\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3950 - loss: 2.2073 - val_accuracy: 0.3378 - val_loss: 2.3641\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4040 - loss: 2.1697 - val_accuracy: 0.3497 - val_loss: 2.3445\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4032 - loss: 2.1880 - val_accuracy: 0.3968 - val_loss: 2.2285\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4044 - loss: 2.1718 - val_accuracy: 0.3636 - val_loss: 2.3209\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4021 - loss: 2.1662 - val_accuracy: 0.3427 - val_loss: 2.3175\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4128 - loss: 2.1637 - val_accuracy: 0.3629 - val_loss: 2.3026\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4067 - loss: 2.1656 - val_accuracy: 0.3926 - val_loss: 2.2508\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4119 - loss: 2.1476 - val_accuracy: 0.2835 - val_loss: 2.5851\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4048 - loss: 2.1757 - val_accuracy: 0.4087 - val_loss: 2.1684\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0892 - loss: 10.1025 - val_accuracy: 0.1377 - val_loss: 5.3432\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1575 - loss: 4.7403 - val_accuracy: 0.1314 - val_loss: 3.5590\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1916 - loss: 3.3198 - val_accuracy: 0.1055 - val_loss: 3.3371\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2077 - loss: 2.9433 - val_accuracy: 0.1431 - val_loss: 3.0793\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2145 - loss: 2.8323 - val_accuracy: 0.1231 - val_loss: 3.2495\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2383 - loss: 2.7372 - val_accuracy: 0.1323 - val_loss: 3.1053\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2460 - loss: 2.6956 - val_accuracy: 0.2094 - val_loss: 2.7893\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2444 - loss: 2.7153 - val_accuracy: 0.1336 - val_loss: 3.0175\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2538 - loss: 2.6863 - val_accuracy: 0.1399 - val_loss: 3.0884\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2544 - loss: 2.6922 - val_accuracy: 0.1477 - val_loss: 3.1049\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2591 - loss: 2.6561 - val_accuracy: 0.1999 - val_loss: 2.8278\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2658 - loss: 2.6410 - val_accuracy: 0.1518 - val_loss: 2.9618\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2685 - loss: 2.6410 - val_accuracy: 0.1467 - val_loss: 3.0486\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2762 - loss: 2.6091 - val_accuracy: 0.2379 - val_loss: 2.7873\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2704 - loss: 2.6395 - val_accuracy: 0.2462 - val_loss: 2.6960\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2685 - loss: 2.6355 - val_accuracy: 0.1007 - val_loss: 3.3083\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2700 - loss: 2.6205 - val_accuracy: 0.2133 - val_loss: 2.7863\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2826 - loss: 2.6017 - val_accuracy: 0.1823 - val_loss: 3.0042\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2772 - loss: 2.6017 - val_accuracy: 0.1955 - val_loss: 2.9183\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2696 - loss: 2.6132 - val_accuracy: 0.1504 - val_loss: 3.0409\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2744 - loss: 2.5983 - val_accuracy: 0.1921 - val_loss: 2.8488\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2910 - loss: 2.5668 - val_accuracy: 0.1557 - val_loss: 2.9789\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2734 - loss: 2.6283 - val_accuracy: 0.1275 - val_loss: 3.0665\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2753 - loss: 2.5964 - val_accuracy: 0.1462 - val_loss: 2.9217\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2812 - loss: 2.5944 - val_accuracy: 0.2474 - val_loss: 2.6827\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2773 - loss: 2.5926 - val_accuracy: 0.2620 - val_loss: 2.6387\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2736 - loss: 2.5949 - val_accuracy: 0.2535 - val_loss: 2.6540\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2774 - loss: 2.5851 - val_accuracy: 0.1769 - val_loss: 2.8971\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2790 - loss: 2.5724 - val_accuracy: 0.2622 - val_loss: 2.6351\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2840 - loss: 2.5507 - val_accuracy: 0.1328 - val_loss: 2.9991\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2854 - loss: 2.5519 - val_accuracy: 0.2028 - val_loss: 2.8748\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2703 - loss: 2.5937 - val_accuracy: 0.1638 - val_loss: 3.0874\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2781 - loss: 2.5712 - val_accuracy: 0.2632 - val_loss: 2.6362\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2828 - loss: 2.5540 - val_accuracy: 0.1509 - val_loss: 2.9571\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2782 - loss: 2.5528 - val_accuracy: 0.1606 - val_loss: 3.0067\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2813 - loss: 2.5579 - val_accuracy: 0.1577 - val_loss: 2.9199\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2713 - loss: 2.5857 - val_accuracy: 0.1835 - val_loss: 2.8512\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2782 - loss: 2.5647 - val_accuracy: 0.1531 - val_loss: 3.2652\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2841 - loss: 2.5485 - val_accuracy: 0.1082 - val_loss: 3.1746\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2845 - loss: 2.5399 - val_accuracy: 0.1401 - val_loss: 3.0084\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2824 - loss: 2.5282 - val_accuracy: 0.1428 - val_loss: 3.0428\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2887 - loss: 2.5224 - val_accuracy: 0.2162 - val_loss: 2.8110\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2881 - loss: 2.5265 - val_accuracy: 0.2079 - val_loss: 2.7713\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2886 - loss: 2.5259 - val_accuracy: 0.1813 - val_loss: 2.8259\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2891 - loss: 2.5194 - val_accuracy: 0.2274 - val_loss: 2.7523\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2968 - loss: 2.5229 - val_accuracy: 0.1648 - val_loss: 2.8993\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2860 - loss: 2.5369 - val_accuracy: 0.2596 - val_loss: 2.6168\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2929 - loss: 2.5150 - val_accuracy: 0.2074 - val_loss: 2.9246\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2987 - loss: 2.5314 - val_accuracy: 0.2164 - val_loss: 2.7264\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2897 - loss: 2.5295 - val_accuracy: 0.1762 - val_loss: 2.8739\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.0749 - loss: 4.2571 - val_accuracy: 0.1189 - val_loss: 3.4792\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1152 - loss: 3.5296 - val_accuracy: 0.1667 - val_loss: 3.2562\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1531 - loss: 3.2626 - val_accuracy: 0.2252 - val_loss: 3.0421\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1915 - loss: 3.0600 - val_accuracy: 0.1830 - val_loss: 3.0165\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2129 - loss: 2.9096 - val_accuracy: 0.1496 - val_loss: 3.0841\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2317 - loss: 2.7959 - val_accuracy: 0.1977 - val_loss: 2.8922\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2449 - loss: 2.7074 - val_accuracy: 0.2059 - val_loss: 2.8376\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2602 - loss: 2.6403 - val_accuracy: 0.1791 - val_loss: 2.8603\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2772 - loss: 2.5777 - val_accuracy: 0.2303 - val_loss: 2.6772\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2806 - loss: 2.5511 - val_accuracy: 0.2289 - val_loss: 2.7725\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2942 - loss: 2.4952 - val_accuracy: 0.2459 - val_loss: 2.6254\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2958 - loss: 2.4853 - val_accuracy: 0.2030 - val_loss: 2.7920\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3045 - loss: 2.4701 - val_accuracy: 0.2059 - val_loss: 2.8461\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3073 - loss: 2.4698 - val_accuracy: 0.2700 - val_loss: 2.5640\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3186 - loss: 2.4436 - val_accuracy: 0.1872 - val_loss: 2.9043\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3229 - loss: 2.4262 - val_accuracy: 0.2986 - val_loss: 2.4439\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3236 - loss: 2.4233 - val_accuracy: 0.2520 - val_loss: 2.6778\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3294 - loss: 2.4049 - val_accuracy: 0.2956 - val_loss: 2.4914\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3243 - loss: 2.4026 - val_accuracy: 0.2371 - val_loss: 2.7425\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3307 - loss: 2.4066 - val_accuracy: 0.2632 - val_loss: 2.6228\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3268 - loss: 2.3987 - val_accuracy: 0.2013 - val_loss: 2.8234\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3364 - loss: 2.3687 - val_accuracy: 0.2895 - val_loss: 2.4977\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3300 - loss: 2.3735 - val_accuracy: 0.2934 - val_loss: 2.4941\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3348 - loss: 2.3839 - val_accuracy: 0.3419 - val_loss: 2.3526\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3406 - loss: 2.3661 - val_accuracy: 0.3151 - val_loss: 2.4320\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3406 - loss: 2.3568 - val_accuracy: 0.2445 - val_loss: 2.6492\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3353 - loss: 2.3911 - val_accuracy: 0.2686 - val_loss: 2.5781\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3335 - loss: 2.3800 - val_accuracy: 0.2898 - val_loss: 2.5352\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3424 - loss: 2.3455 - val_accuracy: 0.3298 - val_loss: 2.3960\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3328 - loss: 2.3759 - val_accuracy: 0.2659 - val_loss: 2.6393\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3288 - loss: 2.3905 - val_accuracy: 0.3203 - val_loss: 2.3785\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3320 - loss: 2.3877 - val_accuracy: 0.2245 - val_loss: 2.7217\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3328 - loss: 2.3591 - val_accuracy: 0.2067 - val_loss: 2.8447\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3349 - loss: 2.3561 - val_accuracy: 0.2888 - val_loss: 2.4938\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3306 - loss: 2.3621 - val_accuracy: 0.2564 - val_loss: 2.6186\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3435 - loss: 2.3480 - val_accuracy: 0.2062 - val_loss: 2.7206\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3418 - loss: 2.3591 - val_accuracy: 0.2735 - val_loss: 2.5259\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3293 - loss: 2.3776 - val_accuracy: 0.2440 - val_loss: 2.6007\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3247 - loss: 2.3768 - val_accuracy: 0.3103 - val_loss: 2.4247\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3402 - loss: 2.3469 - val_accuracy: 0.3081 - val_loss: 2.4452\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3337 - loss: 2.3527 - val_accuracy: 0.2998 - val_loss: 2.4362\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3467 - loss: 2.3254 - val_accuracy: 0.3081 - val_loss: 2.4019\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3374 - loss: 2.3359 - val_accuracy: 0.3692 - val_loss: 2.2459\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3476 - loss: 2.3224 - val_accuracy: 0.3539 - val_loss: 2.2949\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3358 - loss: 2.3377 - val_accuracy: 0.3534 - val_loss: 2.3066\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3408 - loss: 2.3403 - val_accuracy: 0.3775 - val_loss: 2.2313\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3279 - loss: 2.3809 - val_accuracy: 0.2703 - val_loss: 2.6032\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3314 - loss: 2.3615 - val_accuracy: 0.2293 - val_loss: 2.7035\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3385 - loss: 2.3499 - val_accuracy: 0.3315 - val_loss: 2.3533\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3351 - loss: 2.3614 - val_accuracy: 0.2208 - val_loss: 2.8278\n",
      "Epoch 1/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0734 - loss: 10.2739 - val_accuracy: 0.0916 - val_loss: 5.7209\n",
      "Epoch 2/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1145 - loss: 5.1297 - val_accuracy: 0.1375 - val_loss: 3.7358\n",
      "Epoch 3/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1550 - loss: 3.5315 - val_accuracy: 0.1299 - val_loss: 3.1910\n",
      "Epoch 4/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1925 - loss: 3.0141 - val_accuracy: 0.1133 - val_loss: 3.3101\n",
      "Epoch 5/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1921 - loss: 2.8859 - val_accuracy: 0.1236 - val_loss: 2.9819\n",
      "Epoch 6/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2002 - loss: 2.8021 - val_accuracy: 0.1635 - val_loss: 2.8881\n",
      "Epoch 7/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2090 - loss: 2.7719 - val_accuracy: 0.1667 - val_loss: 2.8804\n",
      "Epoch 8/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2129 - loss: 2.7514 - val_accuracy: 0.1460 - val_loss: 2.9192\n",
      "Epoch 9/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2137 - loss: 2.7601 - val_accuracy: 0.1111 - val_loss: 3.0452\n",
      "Epoch 10/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2130 - loss: 2.7469 - val_accuracy: 0.1645 - val_loss: 2.9757\n",
      "Epoch 11/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2219 - loss: 2.7351 - val_accuracy: 0.1448 - val_loss: 2.9392\n",
      "Epoch 12/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2274 - loss: 2.7267 - val_accuracy: 0.1194 - val_loss: 2.9282\n",
      "Epoch 13/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2313 - loss: 2.7036 - val_accuracy: 0.1194 - val_loss: 2.9465\n",
      "Epoch 14/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2317 - loss: 2.6986 - val_accuracy: 0.1623 - val_loss: 2.9048\n",
      "Epoch 15/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2353 - loss: 2.6977 - val_accuracy: 0.1299 - val_loss: 2.9256\n",
      "Epoch 16/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2313 - loss: 2.6984 - val_accuracy: 0.1701 - val_loss: 2.8397\n",
      "Epoch 17/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2410 - loss: 2.6821 - val_accuracy: 0.2113 - val_loss: 2.7855\n",
      "Epoch 18/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2344 - loss: 2.7160 - val_accuracy: 0.1713 - val_loss: 2.8776\n",
      "Epoch 19/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2386 - loss: 2.6803 - val_accuracy: 0.1087 - val_loss: 3.1348\n",
      "Epoch 20/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2410 - loss: 2.6852 - val_accuracy: 0.1438 - val_loss: 3.0403\n",
      "Epoch 21/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2410 - loss: 2.6753 - val_accuracy: 0.1623 - val_loss: 2.8632\n",
      "Epoch 22/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2439 - loss: 2.6614 - val_accuracy: 0.1994 - val_loss: 2.7691\n",
      "Epoch 23/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2389 - loss: 2.6703 - val_accuracy: 0.1718 - val_loss: 2.8799\n",
      "Epoch 24/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2427 - loss: 2.6646 - val_accuracy: 0.1443 - val_loss: 2.9777\n",
      "Epoch 25/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2381 - loss: 2.6704 - val_accuracy: 0.1891 - val_loss: 2.8216\n",
      "Epoch 26/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2390 - loss: 2.6740 - val_accuracy: 0.1121 - val_loss: 2.9672\n",
      "Epoch 27/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2369 - loss: 2.6729 - val_accuracy: 0.1226 - val_loss: 3.0681\n",
      "Epoch 28/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2389 - loss: 2.6720 - val_accuracy: 0.2155 - val_loss: 2.7109\n",
      "Epoch 29/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2454 - loss: 2.6418 - val_accuracy: 0.1323 - val_loss: 2.9999\n",
      "Epoch 30/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2459 - loss: 2.6487 - val_accuracy: 0.1733 - val_loss: 2.8587\n",
      "Epoch 31/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2513 - loss: 2.6205 - val_accuracy: 0.1343 - val_loss: 2.9725\n",
      "Epoch 32/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2528 - loss: 2.6320 - val_accuracy: 0.1621 - val_loss: 2.8575\n",
      "Epoch 33/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2405 - loss: 2.6379 - val_accuracy: 0.2086 - val_loss: 2.7441\n",
      "Epoch 34/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2397 - loss: 2.6307 - val_accuracy: 0.1694 - val_loss: 2.9500\n",
      "Epoch 35/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2424 - loss: 2.6331 - val_accuracy: 0.1657 - val_loss: 2.8338\n",
      "Epoch 36/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2458 - loss: 2.6292 - val_accuracy: 0.1097 - val_loss: 2.9715\n",
      "Epoch 37/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2440 - loss: 2.6421 - val_accuracy: 0.1869 - val_loss: 2.8198\n",
      "Epoch 38/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2483 - loss: 2.6316 - val_accuracy: 0.2442 - val_loss: 2.6507\n",
      "Epoch 39/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2476 - loss: 2.6398 - val_accuracy: 0.1555 - val_loss: 2.8941\n",
      "Epoch 40/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2398 - loss: 2.6538 - val_accuracy: 0.2588 - val_loss: 2.6147\n",
      "Epoch 41/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2431 - loss: 2.6400 - val_accuracy: 0.1857 - val_loss: 2.7841\n",
      "Epoch 42/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2429 - loss: 2.6286 - val_accuracy: 0.1206 - val_loss: 3.0077\n",
      "Epoch 43/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2491 - loss: 2.6376 - val_accuracy: 0.1072 - val_loss: 3.4872\n",
      "Epoch 44/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2500 - loss: 2.6139 - val_accuracy: 0.1728 - val_loss: 2.8095\n",
      "Epoch 45/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2445 - loss: 2.6296 - val_accuracy: 0.2410 - val_loss: 2.6448\n",
      "Epoch 46/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2505 - loss: 2.6255 - val_accuracy: 0.1041 - val_loss: 3.4903\n",
      "Epoch 47/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2493 - loss: 2.6221 - val_accuracy: 0.1487 - val_loss: 2.9476\n",
      "Epoch 48/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2478 - loss: 2.6068 - val_accuracy: 0.1557 - val_loss: 2.8995\n",
      "Epoch 49/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2515 - loss: 2.6226 - val_accuracy: 0.1981 - val_loss: 2.7877\n",
      "Epoch 50/50\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2472 - loss: 2.6185 - val_accuracy: 0.2213 - val_loss: 2.6682\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import os\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "# Define a function to create and compile models\n",
    "def create_model(architecture, dropout_rate, l2_rate):\n",
    "    model = Sequential()\n",
    "    for i, units in enumerate(architecture):\n",
    "        if i == 0:  # First layer\n",
    "            model.add(Dense(units, activation='relu', input_shape=(300,), kernel_regularizer=l2(l2_rate)))\n",
    "        else:\n",
    "            model.add(Dense(units, activation='relu', kernel_regularizer=l2(l2_rate)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define hyperparameters to explore\n",
    "architectures = [\n",
    "    [128, 64],\n",
    "    [256, 128, 64],\n",
    "    [512, 256, 128, 64]\n",
    "]\n",
    "dropout_rates = [0.3, 0.4]\n",
    "l2_rates = [0.001, 0.01]\n",
    "\n",
    "# Create a log directory\n",
    "base_log_dir = \"logs\"\n",
    "os.makedirs(base_log_dir, exist_ok=True)\n",
    "\n",
    "# Experimentation loop\n",
    "for arch, dropout, l2_rate in itertools.product(architectures, dropout_rates, l2_rates):\n",
    "    # Create a meaningful log directory name\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = os.path.join(\n",
    "        base_log_dir,\n",
    "        f\"arch_{'-'.join(map(str, arch))}_dropout_{dropout}_l2_{l2_rate}_{timestamp}\"\n",
    "    )\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    # TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "    \n",
    "    # Build and train the model\n",
    "    model = create_model(arch, dropout, l2_rate)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=50,  # Adjust as needed\n",
    "        batch_size=32,\n",
    "        callbacks=[tensorboard_callback]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1239 - loss: 3.0620\n",
      "Test Accuracy: 12.38%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('model', RandomForestClassifier(n_estimators=200))],\n",
       " 'transform_input': None,\n",
       " 'verbose': False,\n",
       " 'model': RandomForestClassifier(n_estimators=200),\n",
       " 'model__bootstrap': True,\n",
       " 'model__ccp_alpha': 0.0,\n",
       " 'model__class_weight': None,\n",
       " 'model__criterion': 'gini',\n",
       " 'model__max_depth': None,\n",
       " 'model__max_features': 'sqrt',\n",
       " 'model__max_leaf_nodes': None,\n",
       " 'model__max_samples': None,\n",
       " 'model__min_impurity_decrease': 0.0,\n",
       " 'model__min_samples_leaf': 1,\n",
       " 'model__min_samples_split': 2,\n",
       " 'model__min_weight_fraction_leaf': 0.0,\n",
       " 'model__monotonic_cst': None,\n",
       " 'model__n_estimators': 200,\n",
       " 'model__n_jobs': None,\n",
       " 'model__oob_score': False,\n",
       " 'model__random_state': None,\n",
       " 'model__verbose': 0,\n",
       " 'model__warm_start': False}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = load('best_model_rf.joblib')\n",
    "clf_rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        enfj       0.95      0.89      0.92       256\n",
      "        enfp       0.92      0.73      0.82       279\n",
      "        entj       0.99      0.96      0.98       248\n",
      "        entp       0.94      0.87      0.90       236\n",
      "        esfj       1.00      0.99      1.00       251\n",
      "        esfp       1.00      0.97      0.98       245\n",
      "        estj       1.00      0.99      1.00       269\n",
      "        estp       1.00      0.99      1.00       263\n",
      "        infj       0.67      0.69      0.68       259\n",
      "        infp       0.43      0.79      0.56       248\n",
      "        intj       0.86      0.81      0.83       259\n",
      "        intp       0.90      0.68      0.78       274\n",
      "        isfj       0.96      0.94      0.95       252\n",
      "        isfp       0.98      0.96      0.97       241\n",
      "        istj       1.00      0.97      0.98       246\n",
      "        istp       0.99      0.96      0.97       277\n",
      "\n",
      "    accuracy                           0.89      4103\n",
      "   macro avg       0.91      0.89      0.89      4103\n",
      "weighted avg       0.91      0.89      0.89      4103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to Clean the tweets and make them feasible\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "import contractions\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load the spaCy English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def decode_unicode_escape(text):\n",
    "    return re.sub(r'\\\\x([0-9a-fA-F]{2})', lambda m: bytes.fromhex(m.group(1)).decode('utf-8', errors='ignore'), text)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Decode Unicode escape sequences\n",
    "    text = decode_unicode_escape(text)\n",
    "\n",
    "    # Remove Unicode emojis\n",
    "    text = emoji.emojize(text, language='alias')\n",
    "\n",
    "    # Case Standardization\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove the leading \"b'\" and trailing \"'\"\n",
    "    text = re.sub(r\"^b'|'$\", '', text)\n",
    "\n",
    "    # Remove hyperlinks\n",
    "    text = re.sub(r'http\\S*', '', text)\n",
    "\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\S*', '', text)\n",
    "\n",
    "    # Replace \\n and \\n\\n with spaces\n",
    "    text = re.sub(r'\\\\n|\\\\n\\\\n', ' ', text)\n",
    "\n",
    "    # Remove any non-alphabetic characters from the text\n",
    "    text = re.sub(r'[^a-zA-Z\\s]+', '', text)\n",
    "\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\S*', '', text)\n",
    "\n",
    "    # Expand contractions\n",
    "    def expand_contractions(text):\n",
    "        expanded_words = []\n",
    "        for word in text.split():\n",
    "            expanded_words.append(contractions.fix(word))\n",
    "        return ' '.join(expanded_words)\n",
    "\n",
    "    text = expand_contractions(text)\n",
    "\n",
    "    # Lemmatize the text\n",
    "    def lemmatize(text, nlp):\n",
    "        doc = nlp(text)\n",
    "        lemmatized_text = []\n",
    "        for token in doc:\n",
    "            lemmatized_text.append(token.lemma_)\n",
    "        return \" \".join(lemmatized_text)\n",
    "\n",
    "    text = lemmatize(text, nlp)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
    "\n",
    "    # Remove leading '@' tokens that are not valid English words\n",
    "    # cleaned_tokens = [token for token in tokens if not token.startswith('@')]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "tweets_elon_df['clean_content'] = tweets_elon_df['tweet'].apply(clean_text)\n",
    "print(tweets_elon_df['clean_content'].head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3033157,
     "sourceId": 5214169,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5504,
     "sourceId": 8240,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ia-2024-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
